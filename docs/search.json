[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Self-efficacy. A Research Agenda with an International Large-Scale Assessment Insight",
    "section": "",
    "text": "Introduction\nThe Self-Efficacy agenda in digital environments has become increasingly relevant to the changing contemporary world. High levels of self-efficacy enable young people to increase their ability to adapt to new technological environments, facilitating their learning for life in the long term. The concept has even been coined as a second-order digital divide.\nThe research on digital self-efficacy has been extensively investigated, and a large volume of information and data is available. This agenda deploys international studies in the educational field that allow approximations at the country and school level to study the issue.\nAlthough these large-scale international studies have been disseminated and analyzed in countless articles and academic journals, they are generally studied around the problematization of the digital competence or literacy variable, leaving digital self-efficacy in the background. Likewise, most efforts do not tend to stop to compare how all these studies approach the phenomenon of digital self-efficacy in a differentiated manner.\nThe NUDOS social line has the opportunity to open an agenda around digital self-efficacy in educational contexts with an international orientation. This could be beneficial both for increasing understanding of the levels of autonomy in young school children around the world and for amplifying the pace of publications and visibility of the project.\nHowever, to open this agenda, it is first necessary to dive with due dedication into the concept of self-efficacy, how it lands in digital studies, and then how it is taken up by large-scale international educational studies. This paper aims to formalize a research agenda for digital self-efficacy in ILSA studies that will serve as a constant reference for research in the social line of NUDOS.\nFour specific objectives are proposed:\n\nUnderstand Bandura’s theoretical definitions of self-efficacy, as well as its limitations and empirical suggestions.\nDissecting how the concept of self-efficacy was integrated into digital competences discussions.\nCompare how international large-scale educational studies have approached to digital self-efficacy.\nAccumulate evidence on how the digital divide is expressed on levels of digital self-efficacy.\n\nThe manuscript is divided into nine chapters. The first chapter presents the theoretical background of Social Cognitive Theory, explaining how Self-efficacy is part of a deep effort to understand human agency. The second chapter exposes Bandura’s definition of self-efficacy and the concept’s relevance and analytical classifications. The third chapter takes Bandura’s empirical suggestions to measure self-efficacy and then revises the critiques and limitations of his proposal. The fourth chapter describes the relationship between digital competence and digital self-efficacy, detailing how this last one has been studied and theorized. The fifth chapter analyzes how Large Scale Assessment studies have included self-efficacy as a variable of analysis. The sixth chapter compares three specific Large-scale Scale Assessment studies’ approaches to digital self-efficacy—and the seventh chapter discusses their measures and definitions. The eighth chapter presents the concept of the digital divide, and the ninth explores empirical evidence on how the different levels of the digital divide are expressed in digital Self-efficacy. Finally, the tenth chapter concludes with suggestions and next steps for future research in the agenda."
  },
  {
    "objectID": "02_agentic_perspective.html#social-cognitive-theory-on-psychological-debates",
    "href": "02_agentic_perspective.html#social-cognitive-theory-on-psychological-debates",
    "title": "1  The agentic perspective on Social Cognitive Theory",
    "section": "1.1 Social Cognitive Theory on Psychological Debates",
    "text": "1.1 Social Cognitive Theory on Psychological Debates\nThe concept of Self-efficacy cannot be understood if it is not revised by the role that has on Bandura’s Social Cognitive Theory1. This theory emerged to discuss behaviorist and computationalist psychological approaches to studying the human mind and learning process. In particular, this theory tried to focus on the human agency, which the other two currents of thought dealt with reductionism.\nLearning has always been a debate in psychological theory. In the discipline’s early stages, the foundational principles embraced an input-output model of learning. The mechanism that the mind presents was not relevant for the empirical positivistic perspective in the behaviorist current; the objective of psychology was reduced to studying action-reaction phenomena of human behavior. Behind this state, there was an assumption that the mind was a mechanical device, where the stimulations are received invariantly, so the input determines the subject’s response.\nWhen computational thinking started to grow in the second decade of the XX Century, the mind started to be represented as an internal circuit with cognitive operations. As computers, the mind performs complex operations to process information and give solutions to problems presented (inputs). In this way, the mind is a computer operating by pre-ordered rules saved in the neurological network (or hardware). A “throughput” was added to the mind in this second case. The behavioral decisions were now oriented by a process. The multifactorial dynamic throughput computationalist position doesn’t give space for intention or will; opens the mind to learn about problems and make changes in the solution-making process, but it’s a hiper-cognitive approach, which cannot explain decisions by affections, emotions, or imagination.\nFor both perspectives, behaviorists and computationalists, human agency is not present because, to assume agency, there has to be consciousness. The conscience supposes a self-generated purpose in the action. This contemplates not only cognitive operations but also a sense of life of the subject. Bandura’s intention of SCT was to not reduce the conscience activity to an epiphenomenal product of a sub-personal level, either neurological-cognitive aspects or subconsciousness desires. Bandura’s work tried not to ignore human prime features in psychology, such as subjectivity, deliberative self-guidance, and reflective self-reactiveness (banduraSocialCognitiveTheory2001?).\nThen, a definition of SCT can be given: “Consciousness cannot be reduced to a non-functional by-product of the output of a mental process realized mechanical at a non-consciousness lower level”. People act on beliefs, goals, aspirations, and expectations, which are not fully explained by brain or environmental activity. People are agents of experience rather than simply undergoing their experience. We give meaning, direction and satisfaction to our lives. The point is that the consciousness elements can also change the brain and the environment, so they are not epiphenomenal issues. Neurons are plastic to our thinking. We are not only exposed to stimulation, but we agenting acting to it (banduraSocialCognitiveTheory2001?).\nThis agentic perspective fosters a line of research to provide new insights into the social construction of the human brain. Our functional structure changes through our interactions and thoughts. The claim is to “bio-psycho-socialized” the human development. In SCT the mind is not an aggregate of environment or brain. Have emergent properties. The human mind is generative, not reactive. So there’s a double direction of complementation: By one way, integer human intentionality to behavior, for the other, try to limit sociostructural factors and see how it links with psychological mechanisms to produce behavioral effect. This is how Bandura arrives at the Triadical reciprocal causation model of action, where personal/internal factors (organic or mind-intended), Environmental influences and Behavioural patterns have bi-directional mutual determinations between them."
  },
  {
    "objectID": "02_agentic_perspective.html#the-elements-of-human-agency",
    "href": "02_agentic_perspective.html#the-elements-of-human-agency",
    "title": "1  The agentic perspective on Social Cognitive Theory",
    "section": "1.2 The Elements of Human Agency",
    "text": "1.2 The Elements of Human Agency\nHow can the human being’s agentic properties be determined? Bandura gives some definitions. An agentic act is one that is done intentionally, with a representation of a future course of action to be performed. The intention enables the power to direct and plan actions to achieve the intended outcomes. In that way, to portray agency, the actors have to be aware of the consequences of their actions (banduraSelfefficacyMechanismHuman1982?).\nThe human agency is composed of three elements: Forethought, Self-reactiveness (out-oriented –&gt;), and Self-reflectiveness (&lt;– in-oriented).\nForethought: It’s the temporal extension of agency that goes beyond forward-directed planning. Through this exercise, people motivate themselves and guide their actions in anticipation of future events. This forethought, projected for a long-term perspective, gives direction, meaning, and coherence to one’s life. In simple terms, the ability to bring anticipated outcomes to bear on current activities promotes foresight behavior. It enables people to transcend the immediate environment and fit the present into the future.\nSelf-Reactiveness: An agent is not only a forethinker. They need motivation and self-regulation, too. Agency involves the deliberative ability to make choices, but also to give shape to appropriate courses of action and to motivate and regulate those actions. This is the reactiveness dimension. Refer to mechanisms that regulate motivation, affect, and action by self-referent subfunctions.\nSelf-Reflectiveness: Ability to self-examine own functioning. The meta-cognitive capability to reflect upon oneself and adecquate one’s thoughts and actions. Within this element, people evaluate their motivation, values, and meaning of life purposes. It’s to think about our thoughts."
  },
  {
    "objectID": "02_agentic_perspective.html#references",
    "href": "02_agentic_perspective.html#references",
    "title": "1  The agentic perspective on Social Cognitive Theory",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "02_agentic_perspective.html#footnotes",
    "href": "02_agentic_perspective.html#footnotes",
    "title": "1  The agentic perspective on Social Cognitive Theory",
    "section": "",
    "text": "Hereinafter, SCT↩︎"
  },
  {
    "objectID": "03_selfeff_def.html#learning-process-depends-on-mindset",
    "href": "03_selfeff_def.html#learning-process-depends-on-mindset",
    "title": "2  Self-efficacy definitions",
    "section": "2.1 Learning process depends on Mindset",
    "text": "2.1 Learning process depends on Mindset\nLearning theories tend to be concerned with the acquisition of knowledge (Cognitive issues) or execution of response patterns (Behavioral issues) to study performance on an activity. With SCT the discipline started to consider also how Self-referents mechanisms affect the acquisition of competence in a determined task.\nAs motivation and affect elements contain the Self-reactiveness dimension of agency self-regulation, Self-reflectiveness is principally explained by the individual’s self-efficacy level. As a part of the intention of human agency, this concept supposes forethought in its structure. In that sense, Self-efficacy is not a self-perception of the ability to execute an action but an orchestration or continued improvisation of multiple skills to manage the ever-changing situation around mastering an activity. Perceived self-efficacy is concerned by judgments of how well one can execute courses of action required to deal with prospective situations (banduraSelfefficacyMechanismHuman1982?).\nThis concept was so important for Bandura because it occupies a pivotal role in the causal structure of development on Social Cognitive Theory as states that beliefs affect adaptation and change not only in their own right but through their impact on other determinants. i) Efficacy plays a central role in the self-regulation of motivation through goal challenges and outcome expectations. ii) Efficacy determines the challenge to undertake, how much effort to expend in the endeavor, how long to persevere in the face of obstacles and failure, and whether failures are motivating or demoralizing. iii) Efficacy beliefs also play a key role in shaping the courses lives take by influencing the types of activities and environments people choose to get into. In synthesis, efficacy shapes the mindset and the environment, crucial for reinforcing the mastery of the activity to which one is dedicated (banduraSelfefficacyExerciseControl1997?; banduraSelfefficacyChangingSocieties1995?).\nDebating human genetic-environmental determination, Bandura’s Self-efficacy concept states that learning or development exceeds inner capabilities. If one judges oneself as capable of managing new competencies, one can undertake them with better probabilities of achievement. In technical terms, self-efficacy is an internal mediator of the covariation between external or environmental factors and behavior or actions. Also, it is proved that self-efficacy could shape neuron network growth, so it’s a determinant for material-internal conditions of learning."
  },
  {
    "objectID": "03_selfeff_def.html#lines-of-information",
    "href": "03_selfeff_def.html#lines-of-information",
    "title": "2  Self-efficacy definitions",
    "section": "2.2 Lines of information",
    "text": "2.2 Lines of information\nSelf-efficacy is based on four lines of information individuals perceive:\n\nMaster experience. Success builds robust beliefs on self-efficacy. Failure undermines it, especially if it occurs before a sense of self-efficacy is firmly established. Inverse with quick results, which easily discourage if a failure appears.\nVicarious experience. Seeing people like oneself succeed through perseverant effort raises the observer’s belief that one, too, can master comparable activity. The inverse token occurs when observing similar people’s failures.\nSocial persuasion. Convince verbally that you don’t have the capabilities to master some given activities. Discouragement to mobilize effort and sustain it by instilling self-doubts about personal deficiencies resulting from other people’s influences.\nPsychological and emotional states. Stress reaction and tension are signs of vulnerability and poor performance.\n\nThese sources of information are not inherently instructive for the individual. The result depends on their cognitive processing of them (banduraSelfefficacyChangingSocieties1995?). This may vary according to the psychological uniqueness of each person. Four mind mechanisms for processing this information:\n\nCognitive processing. Shape types of scenarios constructed and rehearse them. Visualizing failure or achieving goals of courses of action imagined.\nMotivational processing. There are three elements that are used to understand how motivation is shaped. The first focuses on satisfaction with one performance based on personal attributes (Causal attributions/ Attribution theory). The second focuses on benefits or attainments achieved in the activity (Outcome expectancy/ Expectancy value theory). The third is based on a sense of personal progress in mastering the path (Recognized goals/ Goal theory).\nAffective process. Efficacy affects potential threats and situations that are fraught with dangers. It can modify people’s sense of control. As more control is perceived, there is less anxiety about threats and coping with problematic situations.\nSelection process. Efficacy depends on the types of activities and environment people choose to stay. This decision-making process also shapes the environment to increase/decrease Self-efficacy. As low self-efficacy, low aspiration to take difficult tasks, and less aspiration to take difficult tasks and present resilence coping them."
  },
  {
    "objectID": "03_selfeff_def.html#types-of-self-efficacy",
    "href": "03_selfeff_def.html#types-of-self-efficacy",
    "title": "2  Self-efficacy definitions",
    "section": "2.3 Types of Self-efficacy",
    "text": "2.3 Types of Self-efficacy\nSelf-efficacy is a multidimensional concept that can be explored by different approaches. To propose thematic research around this concept, it’s necessary to distinguish between different types or perspectives.\nIndividual self-efficacy level differ on three distinct but interrelated judgements: Magnitude, Strength, and Generalizability1.\nThe Magnitude of self-efficacy refers to the level of task difficulty one believes is attainable. Individuals with a high self-efficacy magnitude might be expected to perceive themselves as able to accomplish more difficult computing tasks than those with lower self-efficacy judgments. Alternatively, self-efficacy magnitude might be gauged regarding support levels required to undertake a task.\nSelf-efficacy Strength refers to the level of conviction about personal judgment. It also reflects the resistance of self-efficacy to apparently disconfirming information. Individuals with a weak sense of self-efficacy will be frustrated more easily by obstacles to their performance and will respond by lowering their perceptions of their capability. By contrast, individuals with a strong sense of efficacy will not be deterred by difficult problems, will retain their sense of self-efficacy, and as a result of their continued persistence, are more likely to overcome whatever obstacle is present.\nSelf-efficacy Generalizability reflects the degree to which the judgment is limited to a particular domain of activity or not. For example, these domains might be considered to reflect different hardware and software configurations within a computing context. Thus, individuals with high computer self-efficacy generalizability would expect to be able to competently use different software packages and different computer systems, while those with low computer self-efficacy generalizability would perceive their capabilities as limited to particular software packages or computer systems.\nGenerally, Self-efficacy has two ways to be studied: As perceived capabilities for task achievement and as a self-regulatory attitude. Task self-efficacy involves the beliefs that one can or cannot perform a single instance of a circumscribed behavior at different levels of performance. Self-regulatory self-efficacy is the confidence in how one can (or could) achieve tasks in the context of potential barriers. Studies focusing on capabilities usually emphasize the magnitude of the task, i.e., its degree of difficulty or complexity, and the linear achievement of the masterization process. By contrast, studies focused on attitudinal aspects give greater importance to strength to keep self-efficacy levels in difficult contexts. The first approach questions the capability to reach higher and higher levels in the activity domain, and the second focuses on persistance or resistance in the face of adversities presented by an activity (williamsConfoundedSelfEfficacyConstruct2016?). Saying in a different way, (schwarzerSocialcognitivePredictorsHealth2000?) distinguish between action self-efficacy as confidence that the subject can (or could) perform the behavior even when it requires setting goals and planning, and coping self-efficacy as confidence that the subject can (or could) perform the behavior even in the face of initial setbacks or lack of social support.\nSome contributions to this debate suggest five types to classify self-efficacy constructs. What varies across these conceptualizations of self-efficacy is whether the perceived capability to perform the target behavior is to be judged in isolation (i.e., task self-efficacy) or under various conditions, such as in the context of potential barriers (i.e., self-regulatory efficacy), when initiating a new behavior (i.e., initiation self-efficacy), following relapse (i.e., recovery self-efficacy), or in the face of potentially stressful life events (i.e., coping self-efficacy) (marlattSelfefficacyAddictiveBehavior1995?)."
  },
  {
    "objectID": "03_selfeff_def.html#several-others",
    "href": "03_selfeff_def.html#several-others",
    "title": "2  Self-efficacy definitions",
    "section": "2.4 Several others",
    "text": "2.4 Several others\nAfter these theoretical definitions, it’s important to note the empirical performance of the Self-efficacy variable. Bandura provides a lot of information that could be useful for our studies. First note. Self-efficacy doesn’t have a positive linear direction with performance. An individual with higher levels of self-efficacy could present lower levels of task achievement. The same with lower grades of self-efficacy. This is because performance and learning, as Social Cognitive Theory tries to defend, is a situated process, and this depends on context, personal attributes, or the specific nature of the task the individual imagines mastering. Self-efficacy covariation with competencies is tied to gender, age, the social groups around the environments, and so on (banduraSelfefficacyChangingSocieties1995?). 2\nSecond note. Self-efficacy is not only an important predictor of an individual’s competences, but also of the decisions he or she makes in life. In the formation period, the perception of boys’ and girls’ capabilities defines the careers they pursue or their interests and affiliative preferences. A person’s life path depends on competences, interests, and affiliative preferences, all of which are influenced by self-efficacy, especially on educational experience (banduraSelfefficacyChangingSocieties1995?).\nThird note. Incentives are also important for explaining self-efficacy. In Social Cognitive Theory, interests grow from satisfactions derived from fulfilling internal standards and from perceiving self-efficacy obtained from performance accomplishments and other sources of efficacy information. By making self-satisfaction conditional on a certain level of performance mastery, people create self-incentives for their efforts (banduraSelfefficacyChangingSocieties1995?).\nFourth note. The resonance theory raised by (rosaResonanciaSociologiaRelacion2019?) is one of the principal theoretical contributions for sociology. The claim of Rosa is to re-found a sociological approximation that move from the resources and competence question to concern the last and principal problem for social sciences: The relations with the world and good life. In this sense, he takes up Bandura’s effort to think of psychotherapy in positive terms (not as a way of avoiding the pathological), and transfers it to sociology, especially to actual critical theory. Bandura’s self-efficacy is a conceptual pillar of this proposal. In his book observes that the current research on self-efficacy use this concept to explain the expansion of resources and opportunities on individuals (Competences and achievements), but the same Bandura demonstrated that levels of intrinsic motivation with an activity doesn’t grow up with the raise of outcomes, but with the sense that world that the world becomes attainable and speaks to you through your own actions. If resonance theory is taken seriously, the decisive factor in understanding the variation in self-efficacy is not the results perceptions, but the interaction-process of the activity. Then, the increase or reach of individuals’ life chances should not be approximated by opportunities per-se, abstract if one will, but by opportunities to establish vibrant threads and meaningful relationships with the activity being evaluated."
  },
  {
    "objectID": "03_selfeff_def.html#references",
    "href": "03_selfeff_def.html#references",
    "title": "2  Self-efficacy definitions",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "03_selfeff_def.html#footnotes",
    "href": "03_selfeff_def.html#footnotes",
    "title": "2  Self-efficacy definitions",
    "section": "",
    "text": "This Self-efficacy judgments were proposed by (briefSelfWorkOrganizations1981?) years ago but then recovered by (compeauComputerSelfEfficacyDevelopment1995?) to study computer Self-efficacy, so I think it’s important to include them.↩︎\nThis insight support our first ICILS study, where we try to approach the under/overestimation phenomenon on digital Self-efficacy. Also, open possibilities to understand why Self-efficacy empirical studies tends to divide constructs on basic and specialized tasks; probably present different effects because of the nature of this concept.↩︎"
  },
  {
    "objectID": "04_construct_scales.html#banduras-insights",
    "href": "04_construct_scales.html#banduras-insights",
    "title": "3  Constructing Self-efficacy measurements",
    "section": "3.1 Bandura’s Insights",
    "text": "3.1 Bandura’s Insights\nAt the late stage of his large Self-efficacy research agenda, (banduraGuideConstructingSelfefficacy2006?) wrote a standard guide for constructing self-efficacy scales. In this text he takes over some critiques and suggestions around the years and tries to propose a definitive method for operationalize self-efficacy. In this section their most relevants comments are selected and exposed.\nFirst Recommendation: Bandura claim that in human life people cannot mastery every realm of life. Self-efficacy differ by the given pursuits in the area in which it its developed. Thus, the efficacy belief system is not a global trait but a differentiated set of self-beliefs linked to distinct realms of functioning. Multidomain measures are necessary because it reveals the patterning and degree of generality of people’s sense of personal efficacy. There is no all-purpose measure of perceived self-efficacy. Scales of perceived self-efficacy must be tailored to the particular domain of functioning that is the object of interest.\nSecond recommendation: Efficacy items should accurately reflect the construct. Self-efficacy is concerned with perceived capability. The items should be phrased in terms of can do rather than will do. Can is a judgment of capability; will is a statement of intention.\nThird recommendation: Perceived self-efficacy should also be distinguished from other constructs such as self-esteem, locus of control, and outcome expectancies. Perceived efficacy is a judgment of capability; self-esteem is a judgment of self-worth; locus of control is about outcome responsibility (one’s actions or external forces); and outcome expectancies are judgments on the results of the action, not about capabilities to do the action.\nFourth recommendation: A comprehensive self-efficacy assessment would be linked to the behavioral factors that influence people to exercise some control. Behavior is better predicted by people’s beliefs in their capabilities to do whatever is needed to succeed than by their beliefs in only one aspect of self-efficacy relevant to the domain. Thus, multifaceted efficacy scales not only have predictive utility but provide insights into the dynamics of self-management of behavior. If self-efficacy scales are targeted to factors that, in fact, have little or no impact on the domain of functioning, such research cannot yield a predictive relation. In short, self-efficacy scales must be tailored to activity domains and assess the multifaceted ways in which efficacy beliefs operate within the selected activity domain. The efficacy scales must be linked to factors that, in fact, determine quality of functioning in the domain of interest.\nFifth recommendation: Perceived efficacy should be measured against task demands that represent gradations of challenges or impediments to successful performance. Self-efficacy appraisals reflect the level of difficulty individuals believe they can surmount. If there are no obstacles to overcome, the activity is easily performable, and everyone is highly efficacious. The events over which personal influence is exercised can vary widely. It may entail regulating one’s own motivation, thought processes, performance level, emotional states, or altering environmental conditions. The nature of the challenges against which personal efficacy is judged will vary depending on the sphere of activity. Constructing scales to assess self-regulatory efficacy requires preliminary work to identify the forms the challenges and impediments take.\nSixth recommendation: The record of the strength of efficacy beliefs have to be on a 100-point scale, ranging in 10-unit intervals from 0 (“Cannot do”); through intermediate degrees of assurance, 50 (“Moderately certain can do”); to complete assurance, 100 (“Highly certain can do”). Scales that use only a few steps should be avoided because they are less sensitive and less reliable. People usually avoid the extreme positions so a scale with only a few steps may, in actual use, shrink to one or two points. Including too few steps loses differentiating information because people who use the same response category may differ if intermediate steps were included.\nSeventh recommendation: Efficacy scales are unipolar, ranging from 0 to a maximum strength. They do not include negative numbers because a judgment of complete incapability (0) has no lower gradations. Bipolar scales with negative gradations below the zero point that one cannot perform a given level of activity do not make sense (pajaresResponseFormatWriting2001?).\nEigth recommendation: People are asked to judge their operative capabilities as of now, not their potential capabilities or their expected future capabilities. It is easy for people to imagine themselves to be fully efficacious in some hypothetical future."
  },
  {
    "objectID": "04_construct_scales.html#critiques-of-bandura-and-others-proposals",
    "href": "04_construct_scales.html#critiques-of-bandura-and-others-proposals",
    "title": "3  Constructing Self-efficacy measurements",
    "section": "3.2 Critiques of Bandura and others’ proposals",
    "text": "3.2 Critiques of Bandura and others’ proposals\nIn 1984, Cognitive Therapy and Research dedicated a special issue to Bandura’s thesis on self-efficacy. Some relevant scholars commented on Bandura’s theory’s limitations and confusing issues.\nAn article by (eastmanTheoreticalMethodologicalDifficulties1984?) on that issue said that Bandura’s definition of self-efficacy is fundamentally ambiguous regarding the distinction between self-efficacy expectations and outcome expectations. Separating acts (tasks) from outcomes, particularly in complex activities, is difficult in real-life experiences. Many behaviors involve a continuous interplay between actions and their outcomes, making it challenging to assess self-efficacy independently of outcome considerations. The authors express skepticism about the applicability of Bandura’s findings to everyday life, arguing that most psychological issues involve tasks and outcomes that are not clearly defined. They believe this complexity makes it difficult for individuals to assess their self-efficacy accurately.\nThis condition is traduced in empirical problems. The empirical studies conducted by Bandura often assess self-efficacy through tasks that are discrete and limited in scope, which may not adequately capture the broader complexities of real-life situations where multiple outcomes exist. The assessments of self-efficacy in Bandura’s studies do not account for the variability and unpredictability of outcomes that individuals might consider, thus failing to demonstrate that efficacy judgments can be made independently of outcome considerations (marzillierContinuingProblemsSelfefficacy1984?). 1\nRecent contributions have indicated that the self-efficacy definition’s grey area with outcome expectations also affects its relation with motivational mechanisms of action. If individuals do not analytically distinguish, with utmost clarity, efficacy expectations from expected outcomes in action, it is likely that the degree of agency is mostly explained by the motivations that generate the outcomes rather than by perceived singular capabilities. In that sense, Self-efficacy would be an epiphenomenon of motivation rather than a determinant. However, if self-efficacy and motivation are intermingled, there would be confusion in distinguishing the agency’s self-reactiveness and self-reflectiveness moments that Bandura previously suggested (williamsConfoundedSelfEfficacyConstruct2016?).\nAs a result, Researchers on Self-efficacy indicate that the operationalization of the concept needs to avoid assessments that confound the judgments of efficacy and motivation of the action. To rate the confidence in a target behavior, some assessments ask participants whether they would do the action or how confident they are to achieve it. This would be a better strategy than ‘can-do’ scale construction strategies. (kirschSelfefficacyOutcomeExpectancies1995?) explains there are two colloquial uses of the phrase can do. One meaning reflects perceived capability per se based on one’s estimation of their actual capability to perform a task (i.e. the original definition of efficacy expectancy as distinct from outcome expectancy). The second meaning reflects motivation based on—in his examples—anticipated “disgust, embarrassment, guilt, or shame”. The second would be a motivation measurement, not a self-efficacy one. The risk is to interpret “I can do [target behaviour]” as “I will do [target behavior]”.\nThe can/can’t do scale approach would be useful if Self-efficacy is measured as task self-efficacy, this is, focusing on the isolated task, with no context o background. But we know in complex activities this becomes difficult, so it’s better to opt for other strategies such as can-do-motivation one (“I could do it if I would like to do it”)."
  },
  {
    "objectID": "04_construct_scales.html#references",
    "href": "04_construct_scales.html#references",
    "title": "3  Constructing Self-efficacy measurements",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "04_construct_scales.html#footnotes",
    "href": "04_construct_scales.html#footnotes",
    "title": "3  Constructing Self-efficacy measurements",
    "section": "",
    "text": "I add this to the agenda review because I think could be useful for General and Specialized Digital Self-efficacy distinction. If one follow the argument, in General tasks there are more possibilities to discriminate between efficacy expectatives and outcome than on Specialized tasks.↩︎"
  },
  {
    "objectID": "05_digital_selfeff.html#thematic-research-around-self-efficacy",
    "href": "05_digital_selfeff.html#thematic-research-around-self-efficacy",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "4.1 Thematic research around Self-efficacy",
    "text": "4.1 Thematic research around Self-efficacy\nThe concept of self-efficacy has become central to studies in social psychology, especially in the case of thematic disciplines such as health, psychotherapy, education, or citizenship. Anecdotally, for example, there is a whole research agenda that has focused on understanding how individuals’ levels of self-efficacy with respect to their consumption habits could benefit addiction treatment. Likewise, it has been problematized how students’ levels of confidence can strengthen their learning in mathematical matters or the adoption of new languages (klassenSelfefficacyEducationalSettings2010?; lenzSelfEfficacyNursing2002?; mahyuddinRelationshipStudentsSelf2006?).\nIn recent years, a whole thematic research agenda has opened up around self-efficacy in studies of digital inequalities and opportunities. There are various high-scale studies on these issues that have become relevant to how this concept lands for individuals’ use and adoption of technologies in the XXI century. In order to understand this debate, it is necessary to look at the concept of digital competencies."
  },
  {
    "objectID": "05_digital_selfeff.html#digital-competence-and-self-efficacy",
    "href": "05_digital_selfeff.html#digital-competence-and-self-efficacy",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "4.2 Digital Competence and Self-efficacy",
    "text": "4.2 Digital Competence and Self-efficacy\nAt the end of the 20th century, the massification of ICT technologies, as well as the increased use of digital environments in labor and academic environments, turned competence with the internet and ICT relevant for lifelong learning. Then, International organizations, as public policy scholars, then started to discuss how to approach levels of mastery of digital technologies in individuals worldwide.\nDigital Literacy was proposed as a first agenda to understand individuals’ capabilities with emergent technologies and their applications, principally on educational achievement (spanteDigitalCompetenceDigital2018?). Initially, the studies dealing with digital literacy focused on technical knowledge of technologies, such as software specifications and operating systems. As soon as the Internet began to become an everyday space in social life, studies on digital literacy began to problematize issues specific to the relationship that occurs between individuals in digital environments, i.e., communication and navigation skills, increasing the dimensions to the fully informational part (falloonDigitalLiteracyDigital2020?).\nAs the discussion developed, it began to be realized that a question of knowledge or intellect did not mainly determine the development of technological skills, but rather, that it was a multidimensional and heterogeneous problem that brought together issues ranging from the proper use of digital applications to the formation of a ‘mindset’ or attitudinal dispositions towards technologies that would be beneficial for learning how to relate with them. Self-efficacy would be a domain of this attitudinal aspect of technology adoption and learning. As an alternative to the digital literacy agenda, digital competences began to be discussed (ulfert-blankAssessingDigitalSelfefficacy2022?).\nDigital Competence (DigComp) is defined as “the confident, critical and responsible use of, and engagement with, digital technologies for learning, at work, and for participation in society”. It encompasses a combination of knowledge, that is, understanding how digital systems may be used, how they function, and how to judge their capabilities or restrictions. Also include skills: “to use, access, filter, evaluate, create, program, and share digital content”, as well as to “protect, information, content, and digital identities”, and attitudes, including the reflective and critical handling of these systems.\nA lot of scales operationalize DigComp as a unidimensional concept with different significations. As a standardized alternative, The European Digital Competence Framework for Citizens proposes five domains:\n\n\n\n\n\n\n\n\n\nCompetence.area\nCompetence\n\n\n\n\n1. Information and data literacy\n1.1 Browsing, searching and filtering data, information and digital content\n\n\n1. Information and data literacy\n1.2 Evaluating data, information and digital content\n\n\n1. Information and data literacy\n1.3 Managing data, information and digital content\n\n\n2. Communication and collaboration\n2.1 Interacting through digital technologies\n\n\n2. Communication and collaboration\n2.2 Sharing through digital technologies\n\n\n2. Communication and collaboration\n2.3 Engaging in citizenship through digital technologies\n\n\n2. Communication and collaboration\n2.4 Collaborating through digital technologies\n\n\n2. Communication and collaboration\n2.5 Netiquette\n\n\n2. Communication and collaboration\n2.6 Managing digital identity\n\n\n3. Digital content creation\n3.1 Developing digital content\n\n\n3. Digital content creation\n3.2 Integrating and re-elaborating digital content\n\n\n3. Digital content creation\n3.3 Copyright and licenses\n\n\n3. Digital content creation\n3.4 Programming\n\n\n4. Safety\n4.1 Protecting devices\n\n\n4. Safety\n4.2 Protecting personal data and privacy\n\n\n4. Safety\n4.3 Protecting health and well-being\n\n\n4. Safety\n4.4 Protecting the environment\n\n\n5. Problem-solving\n5.1 Solving technical problems\n\n\n5. Problem-solving\n5.2 Identifying needs and technological responses\n\n\n5. Problem-solving\n5.3 Creatively using digital technologies\n\n\n5. Problem-solving\n5.4 Identifying digital competence gaps\n\n\n\n\n\nThe current operationalization includes Safety and Problem-solving, which are not regarded in the majority of measures of digital competence. The last one, when is studied, mainly addresses solving technical problems. In contrast, DigComp highlights the skill of utilizing digital systems for solving various problems, not being limited to technical error. In this way, problem-solving also includes the aspect of being aware of one’s own competences and detecting competency gaps. Furthermore, competently dealing with risks and safety digital concerns offers an overview of Digital Self-efficacy, which is an important element in explaining the formation of the five digital competence domains. In this way, DigComp emphasizes this variable, which is minimized in the case of digital literacy definitions (ulfert-blankAssessingDigitalSelfefficacy2022?)."
  },
  {
    "objectID": "05_digital_selfeff.html#an-evolution-of-the-concept",
    "href": "05_digital_selfeff.html#an-evolution-of-the-concept",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "4.3 An evolution of the concept",
    "text": "4.3 An evolution of the concept\nOne reason Bandura devoted so much effort and depth to his theory of self-efficacy is that he was aware that in societies with ever-increasing rates of change, it would become increasingly necessary to have individuals capable of constantly acquiring new skills and thus navigating fast and uncertain times with their due capacity to adapt (banduraSelfefficacyChangingSocieties1995?).\nSociety has changed at an accelerated pace in different aspects up to the present day. One of the most rapidly changing areas today is the development of digital technologies. Year by year the devices, patterns and uses of these technologies are modified, which requires users an unfinished learning process. Given these conditions, self-efficacy has become central than ever to strengthen the ability to adapt to new digital environments. Digital Self-efficacy is an important predictor of learning outcomes with technologies, under/overestimation of competences, knowledge creation and acceptance of technological change (adoption of new ICT’s)(@ ulfert-blankAssessingDigitalSelfefficacy2022?).\nHowever, like the DigComp concept, several different approaches have conceptualized self-efficacy in digital environments over the years. The first antecedents of self-efficacy applied to digital issues resorted to ‘Computer self-efficacy’. (compeauComputerSelfEfficacyDevelopment1995?) proposed this early instrument focused on general computer domains and specific software application tasks. Defined as an individual’s perceptions of his or her ability to use computers in the accomplishment of a task (ie., using a software package for data analysis, writing a mailmerge letter using a word processor), rather than reflecting simple component skills (ie., formatting diskettes, booting up a computer, using a specific software feature such as “bolding text” or “changing margin”). The computer self-efficacy construct was criticized and overcome for neglecting the changing dynamics of digital systems, which extender the digital enviroment over computers. The items of these scales tend to become outdated rapidly (weigelTechnicalProficiencySuccess2014?).\nWhile the increasing importance of interconnection with technologies, the focus was on general one’s judgment of confidence regarding different tasks related to internet use. Internet self-efficacy focuses on what a person believes he or she can accomplish online now or in the future. It does not refer to a person’s skill at performing specific Internet-related tasks, such as writing HTML, using a browser, or transferring files, for example. Instead, it assesses a person’s judgment of their ability to apply Internet skills in a more encompassing mode, such as finding information or troubleshooting search problems. Internet self-efficacy may be distinguished from computer self-efficacy as the belief that one can successfully perform a distinct set of behaviors required to establish, maintain, and utilize effectively the Internet over and above basic personal computer skills (eastinInternetSelfEfficacyPsychology2000?) 1.\nAlthough this new construct partially addressed the obsolescence of technologies, the set of digital activities was reduced to a particular domain, as is the case with the Internet. An ICT Self-efficacy scale was proposed to comprise Computer and internet tasks on the same construct. ICT Self-efficacy construct considers digital information processing or communication (aesaertExploringFactorsRelated2014?; hatlevikStudentsICTSelfefficacy2018?) and more advanced skills, such as programming (rohatgiRoleICTSelfefficacy2016?). Although to its new measures, ICT Self-efficacy usually presents unidimensional concepts or focuses on specific application domains (using ICT for work, school, or leisure) rather than competencies applicably for general life domains (ulfert-blankAssessingDigitalSelfefficacy2022?).\nThe Current measures presented have common limitations in various ways. First, they often do not consider more recent frameworks of digital competences, such as the DigComp, regarding their level of generality, the competences included, and their multidimensionality. The DigComp describes digital competences in terms of general actions (i.e., tasks, functions), such as protecting devices or managing data, that can be applied to a heterogeneous group of individuals and are independent of specific digital systems. Most DSE scales are still system (e.g., specific computer software) or technology-specific (e.g., data storage such as floppy disc) and may thus become outdated. Second, critical competence areas, such as safety and problem-solving are often disregarded. Most of the scales focus on the informational, communicative, and creative aspects of the technologies without exhaustively capturing their dimensions of mastery. Third, the term DSE has been used interchangeably for measuring general competence beliefs (i.e., including items assessing self-concept, another competence belief) or actual proficiency. As a result, this has led to inconsistencies in the representation of the DSE construct in the literature. This is in spite of self-efficacy literature offering clear definitions of how measures should be constructed and its well-defined differentiation from related constructs, such as self-concept (ulfert-blankAssessingDigitalSelfefficacy2022?)"
  },
  {
    "objectID": "05_digital_selfeff.html#standar-dse-scale-based-on-digcomp",
    "href": "05_digital_selfeff.html#standar-dse-scale-based-on-digcomp",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "4.4 Standar DSE Scale based on DigComp",
    "text": "4.4 Standar DSE Scale based on DigComp\n(ulfert-blankAssessingDigitalSelfefficacy2022?) suggests that to reach a high-level of research on Digital Self-efficacy, scales have to (1) be theoretically-grounded multi-dimensional measures of DSE, encompassing diverse digital competence areas, (2) cover different functions and tasks of digital systems, (3) be independent of a specific digital system (e.g., Word), (4) be also labor or economical, not only educational-oriented.\nThen, they propose a scale, which is an actual referent on the Digital Self-efficacy Research Agenda. They follow the approach suggested by (banduraGuideConstructingSelfefficacy2006?) to measure self-efficacy. The scale is formulated generically and adapted to each specific dimension. According to the document, the questions use expressions such as “I am confident that I can…” or “I believe I am able to…”.\nThese questions are customized to reflect each specific competency or task within the digital self-efficacy dimensions defined in the DigComp framework.\n\n\n\n\n\n\n\n\n\nItems\nDimension/Subscale\n\n\n\n\nsearch for specific information in digital environments.\nInformation and data literacy (iSE)\n\n\ndistinguish between correct and incorrect digital information.\nInformation and data literacy (iSE)\n\n\nstore and organize digital content so that I can easily find it again.\nInformation and data literacy (iSE)\n\n\ninteract with others in digital environments.\nCommunication and collaboration (cSE)\n\n\nshare information and data with others digitally.\nCommunication and collaboration (cSE)\n\n\nparticipate in public discussions and activities in digital environments.\nCommunication and collaboration (cSE)\n\n\nDefend myself against injustice in digital environments.\nCommunication and collaboration (cSE)\n\n\nDefend myself and others against injustice in digital environments.\nCommunication and collaboration (cSE)\n\n\nPush back against injustice in digital environments.\nCommunication and collaboration (cSE)\n\n\nuse digital systems to collaborate with others.\nCommunication and collaboration (cSE)\n\n\nuse the proper etiquette to communicate in digital environments.\nCommunication and collaboration (cSE)\n\n\nmanage and delete my digital footprint.\nCommunication and collaboration (cSE)\n\n\npresent myself the way I want in digital environments.\nCommunication and collaboration (cSE)\n\n\ncreate digital content.\nDigital content creation (dSE)\n\n\nchange digital content in a way that new content is created.\nDigital content creation (dSE)\n\n\nidentify legal aspects in digital environments, such as terms of use and licenses.\nDigital content creation (dSE)\n\n\nwrite a simple command in a programming language.\nDigital content creation (dSE)\n\n\nprotect my digital devices from unwanted access.\nSafety (sSe)\n\n\nprotect my personal data in digital environments.\nSafety (sSe)\n\n\nrecognize health risks associated with using digital environments.\nSafety (sSe)\n\n\nuse digital environments to promote my health.\nSafety (sSe)\n\n\nrecognize the impact of digital environments on nature and the climate.\nSafety (sSe)\n\n\nidentify technical problems when using digital environments.\nProblem-solving (pSE)\n\n\nfind and apply various solutions to technical problems that arise.\nProblem-solving (pSE)\n\n\nfind the right digital system to meet non-technical challenges.\nProblem-solving (pSE)\n\n\ndevelop novel digital solutions.\nProblem-solving (pSE)\n\n\nidentify and improve the digital skills I lack.\nProblem-solving (pSE)\n\n\n\n\n\nResponses are obtained on a 6-point Likert scale ranging from “strongly disagree” to “strongly agree”."
  },
  {
    "objectID": "05_digital_selfeff.html#references",
    "href": "05_digital_selfeff.html#references",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "05_digital_selfeff.html#footnotes",
    "href": "05_digital_selfeff.html#footnotes",
    "title": "4  Assesing Digital Self-efficacy",
    "section": "",
    "text": "A particularly useful contribution to our work made by this construct is that it was one of the first to differentiate between basic and advanced tasks, as did the paper by (hsuInternetSelfefficacyElectronic2004?), which divided a general ISE (GISE) and Web-specific self-efficacy (WSE). The first was oriented to general tasks on internet, while the second on an specific web-site domain.↩︎"
  },
  {
<<<<<<< Updated upstream
<<<<<<< Updated upstream
    "objectID": "08_hits_misses.html#a-comparison-of-operazionalization-strategies",
    "href": "08_hits_misses.html#a-comparison-of-operazionalization-strategies",
    "title": "7  Hits and misses in ILSA’s digital Self-efficacy approaches",
    "section": "7.1 A comparison of operazionalization strategies",
    "text": "7.1 A comparison of operazionalization strategies\nAs can be read, these three ILSA studies have different theoretical approaches to Digital Self-efficacy. Because of their limitations, one of them will likely focus on some dimensions of the concept of self-efficacy and another on other elements. The following section is a comparative analysis of the orientations and definitions of each study in relation to the conceptual discussions of Self-efficacy.\nICILS presents a task orientation on self-efficacy concept in both cycles it presents. The questions ask if students can or cannot do concrete activities with technologies, leaving out self-regulatory elements of the concept. In the items there’s not query on levels of confidence or comfortability in the doing-task process. In that sense, ICILS focus on the magnitude of task achievement over strength. The concern is around the grades or levels of masterization on digital devices handling in isolation. This same approach explains why is the unique ILSA which divides a priori the Self-efficacy batteries in two: the first for a minus level of complexity in the masterization and the second for a more advance state of that process.\nBoth batteries of this study in 2013 and 2018 cycles are named as ‘ICT Self-efficacy’, which is consistent with the development of the debate on digital Self-efficacy (Ulfert-Blank & Schmidt, 2022). 2010’s were the epoche were Computer and Internet Self-efficacy were synthetized with ICT self-efficacy. It is noticeable that ICILS’ scales not only measure technical or informative tasks (as do the Computer self-efficacy approach), such as application development or file manipulation, but also others of evaluative nature and digital content creation. Likewise, it’s important to note that the scale is computer-device oriented, most of the tasks listed cannot be done in smartphones or other digital systems less powerful to process information.\nICILS’s statement again demonstrates its focus on digital literacy over a comprehensive understanding of digital competences. The question looks at “How well” the task is done, seeking to orient the concept to a sense of neatness or perfection of accomplishment, over levels of confidence in the process. Regarding the phrasing of the responses, ICILS has a battery consistent with the recommendations of the specialized literature on self-efficacy measurements (Bandura, 2006; Pajares & Schunk, 2002; Williams & Rhodes, 2016), in that it avoids can-do statements, and opts for a strategy that divides individuals who declare they know from those who declare they do not know but believe they could learn, as well as those who declare they are unable to do so. However, the relatively categorical nature with which the battery responses are composed tends to limit the analysis of individuals’ nuances and degrees of self-efficacy.\nPISA presents an inconsistent approach to measuring self-efficacy. In the 2018 version, both the statement and the items refer to the self-regulatory dimension of the concept, specifically with coping self-efficacy. The statement puts the individual in a context when asking for his or her own experience with digital devices. Then, some items ask explicitly for levels of comfort and others encourage the individuals to think about their own interpersonal relations (friends, family, etc.) before they judge their own level of self-efficacy. 2023 version makes a qualitative leap. The scale opts for a battery more similar to ICILS approach, where the statement assumes individual isolation, and the items identify concrete digitally mediated tasks to be solved.\nAlthough PISA does not add to its documentation a specific terminology to refer to digital self-efficacy, it is clear that in 2018 they presented a rather fuzzy concept approaching self-efficacy for the general use of digital devices, which does not specify specific tasks applicable in different systems. In that sense, it is difficult to encapsulate this proposal within the debate identified by Ulfert-Blank & Schmidt (2022). In the case of 2022, the items presented are in tune with the most recent Digital self-efficacy concept, as identify not only digital literacy aspects but digital creation, security and problem-solving too, independently of digital systems. If the analysis enters in details, even if the approach connect with actual standards and suggestions to measure the concept, in any case does not take into account the complexity of security and problem-solving dimensions, leaving only one minimal item for both competences.\nWith respect to the response wording, PISA proposals let researchers delve into numerical levels of self-efficacy, as they present more than three alternatives, with a clearly ordinal disposition. In both cycles, the responses determine grades of agreement in the achievement of the tasks deployed using the strategy suggested by Bandura (2006) and Williams & Rhodes (2016) of not dichotomizing between being able or not being able to do the task, but rather establishing levels of security to be able to achieve it.\nTIMMS declares explicitly the adoption of the ‘Digital Self-efficacy’ terminology, but this does not guarantee that it complies with the multidimensional and heterogeneous standards Ulfert-Blank & Schmidt (2022) suggests. The 2019 cycle have a very basic and minimalistic approach to digital efficacy expectancy. The tasks measured are excessively general and simple, as ‘use a touchscreen’ or ‘edit on a computer’. Although the items phrasing shows that the scale has a good balance between task and self-regulatory approach to self-efficacy, results to be are so abstract that they lose their specificity. The 2023 cycle presents major levels of complexity, but ignores tasks out of informational, evaluative, or creative skills with technologies, such as problem-solving or security. The battery is short and does not allow for a deeper dive into the concept of digital self-efficacy as discussed by Ulfert-Blank & Schmidt (2022).\nAs PISA, TIMMS in both cycles subscribe to a level of agreement on task achievement strategy. The measure let identify grades of Self-efficacy, but distinguishing whether individual can/cannot achievement or not.\nIn summary, it can be pointed out that ICILS emphasizes to a greater extent the ICT operational and technical aspects of the technologies, proposing two measures that linearly increase the degrees of complexity of the tasks, and excluding the attitudinal aspect in this process. While PISA details to a greater extent the mechanisms of self-regulation that accompany the concept of self-efficacy and Digital Competence, although it presents inconsistencies between its cycles. And finally, TIMMS has a minimalist strategy that does not give enough emphasis to digital self-efficacy to deepen the debates surrounding the concept."
  },
  {
    "objectID": "08_hits_misses.html#suggestions-from-team-nudos",
    "href": "08_hits_misses.html#suggestions-from-team-nudos",
    "title": "7  Hits and misses in ILSA’s digital Self-efficacy approaches",
    "section": "7.2 Suggestions from Team NUDOS",
    "text": "7.2 Suggestions from Team NUDOS\nUna vez que discutamos en profundidad estos resultados, sería pertinente armar una propuesta o sugerencias para los tres estudios ILSA que vaya acorde a sus enfoques…\n\n\n\n\nBandura, A. (2006). Guide for constructing Self-efficacy scales. In Self-Efficacy Beliefs of Adolescents. IAP.\n\n\nPajares, F., & Schunk, D. H. (2002). Chapter 1 - Self and Self-Belief in Psychology and Education: A Historical Perspective. In J. Aronson (Ed.), Improving Academic Achievement (pp. 3–21). Academic Press. https://doi.org/10.1016/B978-012064455-1/50004-X\n\n\nUlfert-Blank, A.-S., & Schmidt, I. (2022). Assessing digital self-efficacy: Review and scale development. Computers & Education, 191, 104626. https://doi.org/10.1016/j.compedu.2022.104626\n\n\nWilliams, D., & Rhodes, R. E. (2016). The Confounded Self-Efficacy Construct: Review, Conceptual Analysis, and Recommendations for Future Research. Health Psychology Review, 10(2), 113–128. https://doi.org/10.1080/17437199.2014.941998",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hits and misses in ILSA's digital Self-efficacy approaches</span>"
    ]
  },
  {
    "objectID": "09_digital_divide_framework.html#digital-divide-framework",
    "href": "09_digital_divide_framework.html#digital-divide-framework",
    "title": "8  Digital Divide Framework",
    "section": "",
    "text": "Eastin, M. S., & LaRose, R. (2000). Internet Self-Efficacy and the Psychology of the Digital Divide. Journal of Computer-Mediated Communication, 6(1), 0–0. https://doi.org/10.1111/j.1083-6101.2000.tb00110.x\n\n\nLythreatis, S., Singh, S. K., & El-Kassar, A.-N. (2022). The digital divide: A review and future research agenda. Technological Forecasting and Social Change, 175, 121359. https://doi.org/10.1016/j.techfore.2021.121359",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Digital Divide Framework</span>"
    ]
  },
  {
    "objectID": "10_digital_selfeff_divide.html#first-self-efficacy-divide-access",
    "href": "10_digital_selfeff_divide.html#first-self-efficacy-divide-access",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.1 First Self-efficacy divide: access",
    "text": "9.1 First Self-efficacy divide: access\nAccess is positioned as a crucial variable for Digital Self-Efficacy (DSE), as it represents the first element of the digital divide problematized in academic studies. Recent literature highlights a positive relationship between greater access to technology and higher levels of DSE. Stone (2020) identifies a significant relationship between increased access to ICT and greater self-efficacy in the domains of basic computing, internet use, applications, and content creation. Previous studies have also documented this relationship (Tondeur, Sinnaee, Van Houtte, & Van Braak, 2011, as cited in Hatlevik et al. (2018); Aesaert & Van Braak, 2014; Tsai & Tsai, 2010; Zhong, 2011, as cited in Senkbeil (2023)).\nDue to the simplicity of the dichotomy between access and lack of access to technology, multiple dimensions of access disparities to ICT have been proposed. A study by Ball et al. (2020) examines how these various dimensions relate to DSE, dividing it into Technology Self-Efficacy (TSE) and Application Self-Efficacy (ASE). Among the key findings, a significant relationship was observed between access to and use of computers at home and TSE; however, no such relationship was found with ASE."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#the-socio-economic-divide",
    "href": "10_digital_selfeff_divide.html#the-socio-economic-divide",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.2 The socio-economic divide",
    "text": "9.2 The socio-economic divide\nThe relationship between DSE and socioeconomic variables has also garnered academic interest, focusing on the connection between technological self-efficacies and factors such as cultural capital, parental education, and income. Hatlevik et al. (2018a) found that ICT self-efficacy significantly increases with higher socioeconomic status in 11 countries. Similarly, Chen & Hu (2020), using PISA 2015 data, identified a significant relationship between socioeconomic level and ICT self-efficacy, although the effect was not very strong (varying across countries between 0.0241 and 0.1678). Additionally, Chikezie (2024) reported that socioeconomic status is a significant predictor of technological self-efficacy. In contrast, Stone (2020) did not find a significant relationship between parental income (as reported by university students) and technology-related self-efficacy. Lastly, Bonanati & Buhl (2022) demonstrated a relationship between parental social capital and technological self-efficacy.\nIn summary, although there is a relationship between socioeconomic status and self-efficacy, this effect ranges from low to moderate and is not consistent across all countries. For this reason, it seems important to delve deeper into this relationship, considering various factors that determine household socioeconomic status. This is particularly relevant given that socioeconomic status consistently has the most significant effect on CIL across 14 countries (Hatlevik et al. (2018a)).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Digital Self-efficacy Divide</span>"
    ]
  },
  {
    "objectID": "10_digital_selfeff_divide.html#the-gender-divide",
    "href": "10_digital_selfeff_divide.html#the-gender-divide",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.3 The gender divide",
    "text": "9.3 The gender divide\nGender has been a significant variable in studies on Digital Self-Efficacy (DSE). It is considered important due to the historical gender digital divide across all three levels and because DSE serves as an essential predictor of Computer and Information Literacy (CIL) (Hatlevik et al. (2018a)). Moreover, DSE partially mediates gender differences in CIL and Computational Thinking (Campos & Scherer (2024)). Historically, a gender gap favoring males has been observed, with men displaying higher DSE and more positive attitudes toward technology (Whitley, 1997, as cited in Cai et al. (2017)). However, more recent studies highlight inconsistencies in the direction of this relationship (Cai et al. (2017)). For instance, one study finds that men demonstrate higher technological self-efficacy (Yau and Cheng, 2012, as cited in Cai et al. (2017); Fraillon, 2014), another reports no significant differences (Compton, Burkett, and Burkett, 2003, as cited in Cai et al. (2017)), and some even indicate a reversed relationship (Compton et al., 2003, as cited in Cai et al. (2017); Ray et al., 1999, as cited in Cai et al. (2017)). As a result, numerous studies continue to scrutinize the relationship between various types of technological self-efficacy (ICT self-efficacy, internet self-efficacy, DSE, etc.) and gender.\nA meta-analysis by Cai et al. (2017) highlights that men exhibit better attitudes toward technology, including self-efficacy. Notably, the technological self-efficacy gap between men and women is the most reduced across years among those examined in the study. Additionally, Scherer & Siddiq (2015), using teacher questionnaire data from ICILS 2013, identify a relationship between being male and having higher computational self-efficacy. Contrary to these findings, a study by Hatlevik et al. (2018a) using ICILS 2013 data reveals that women exhibit higher ICT self-efficacy, with effects ranging from 0.04 to 0.15 across nine sampled countries. Consistent with Hatlevik’s findings, Chen and Hu (2020), using PISA 2015 data, report a negative effect of being male on ICT self-efficacy, varying between -0.4369 and -0.1236 depending on the country.\nGiven the inconsistent results from studies on the relationship between gender and DSE, the construct has been segmented to better understand this complex relationship. As previously mentioned, two dimensions of DSE have been proposed: a basic dimension addressing tasks such as internet searches, communication, and social media use, and a specialized dimension involving more complex skills like programming or server management. Gebhardt et al. (2019) and Castillo et al. (2025) (a study conducted solely in Chile) argue, using ICILS 2018 data, that women have higher basic DSE, while men score higher on average in specialized DSE.\nDeparting from studies that rely on Large Assessment Study data (which, according to this review, are predominant), Stone (2020) developed a questionnaire comprising various batteries to measure different dimensions of technology-related self-efficacy. Administered to university applicants in the United States (n=260), the study found that women scored higher in the social media dimension (5.0 vs. 4.0, p&lt;0.01), while men scored higher in the basic computing dimension (3.79 vs. 3.48, p&lt;0.05).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Digital Self-efficacy Divide</span>"
    ]
  },
  {
    "objectID": "10_digital_selfeff_divide.html#second-divide-variables",
    "href": "10_digital_selfeff_divide.html#second-divide-variables",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.4 Second divide variables",
    "text": "9.4 Second divide variables\nThe second level of the digital divide encompasses attitudes, skills, behaviors, and technology-related uses, which recent literature highlights as significant predictors of DSE. Multiple studies have explored the relationship between specific types of ICT use, attitudes toward ICT, ICT-related learning environments, and technological self-efficacy. For instance, a study by Chen & Hu (2020) confirms that interest is positively and significantly related to DSE. Additionally, it finds that ICT use for leisure and socialization are important mediators of this effect, whereas ICT use at school or for school-related tasks is not. This finding is supported by numerous studies; for example, Ball et al. (2020) demonstrates that using ICT to talk with friends or play video games significantly affects technological self-efficacy. Similarly, Hori & Fujii (2021) show that ICT use in schools does not impact self-efficacy, whereas ICT use at home for learning and leisure significantly does.\nThe above suggests that the development of high technological self-efficacy in an individual occurs primarily in the home environment, particularly influenced by the context of learning, use, and types of technology usage. Bonanati & Buhl (2022) explore the relationship between characteristics of the home learning environment and ICT self-efficacy. The authors reveal that children whose parents engage in more online activities with them tend to have higher self-efficacy and identify a relationship between parental attitudes and their children’s self-efficacy. In line with this, Hammer et al. (2021) demonstrate that parental values and beliefs are related to children’s digital self-efficacy; however, this relationship is mediated only by the age at which children are given smartphones. Relatedly, Lai et al. (2022) argue that greater smartphone use is positively associated with DSE, though problematic uses and cases where the relationship is reversed also exist.\nHatlevik et al. (2018a) finds that autonomous learning is positively related to ICT self-efficacy, making it the most consistently observed relationship across countries. Eastin & LaRose (2000) discover that outcome expectations are also linked to DSE, as is internet use experience, which is identified as the best predictor in their study.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Digital Self-efficacy Divide</span>"
    ]
  },
  {
    "objectID": "10_digital_selfeff_divide.html#school-and-country-level",
    "href": "10_digital_selfeff_divide.html#school-and-country-level",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.5 School and country level",
    "text": "9.5 School and country level\nStudies addressing digital self-efficacy (DSE) typically involve different nested levels, as they are mostly conducted using data from International Large-Scale Assessments (ILSA). However, the school level is often not a significant variable. For example, Chen & Hu (2020) conducted a multilevel model including schools across 30 countries, finding that the intraclass correlation (ICC) was less than 0.05 in all countries, with the sole exception of Mexico. Similarly, Juhaňák et al. (2019) found that the ICC was below 0.05 in all countries in their sample (using PISA 2015 data from 21 countries), concluding that only 0.09% of perceived ICT competence could be explained by school characteristics. These results are replicated in ICILS 2013, where Hatlevik et al. (2018b) found that the variation explained by schools was less than 6% in all countries, with Turkey being the only exception. An ICC below 0.05 is commonly conceptualized as small in the context of educational studies. A previous study corroborates these findings, dating back to PISA 2003 (ICC = 0.044) and PISA 2006 (ICC = 0.05, barely reaching the threshold) (Zhong, 2011).\nPossible explanations for this emerge from the literature review, suggesting that ICT use in schools, as opposed to ICT use for leisure or socialization, is not a relevant variable for explaining DSE (Ball et al., 2020; Chen & Hu, 2020; Hori & Fujii, 2021). Additionally, one article finds that the use of ICT at home for school-related tasks is a less significant mediator than other ICT-related variables (Juhaňák et al., 2019). A potential hypothesis (arising purely from the author’s intuition) is that digital self-efficacy is reinforced by motivation, which, in the context of technology, might develop more robustly in leisure activities or communication-based activities, such as social media or video games. School activities, and increased ICT adoption in these, might discourage students from developing their digital skills as they associate them with an unavoidable responsibility.\nAt the country level, for similar reasons as at the school level, it is sometimes included in the analysis. Whether as an additional hierarchical level in the model or through models applied individually to each country, several studies have identified heterogeneity in self-efficacy across countries, as well as in the effect sizes of the independent variables employed. For instance, Zhong (2011) found a higher correlation between classes at the country level than at the school level, with values of 0.077 in PISA 2003 and 0.079 in PISA 2006. However, the inclusion of the country level is usually aimed only at visualizing the heterogeneity or homogeneity of an effect, without specifically focusing on the relationship between country-level dependent variables and self-efficacy or even their effects. This is the case with studies such as those by Hatlevik et al. (2018b) and Chen & Hu (2020), for example.\nHowever, future research needs to identify explanations for these differences, which intuitively could stem from various reasons. For instance, the degree of connectivity and technological infrastructure achieved in a country might be a significant factor influencing technology-related self-efficacy, as the population would have different levels of exposure to and familiarity with ICT. Thus, exploring various explanations for this heterogeneity is essential, as it is crucial to address digital inequalities between countries with differing levels of technological development.\n\n\n\n\nBall, C., Huang, K.-T., Francis, J., Kadylak, T., & Cotten, S. R. (2020). A Call for Computer Recess: The Impact of Computer Activities on Predominantly Minority Students’ Technology and Application Self-Efficacy. American Behavioral Scientist, 64(7), 883–899. https://doi.org/10.1177/0002764220919142\n\n\nBonanati, S., & Buhl, H. M. (2022). The digital home learning environment and its relation to children’s ICT self-efficacy. Learning Environments Research, 25(2), 485–505. https://doi.org/10.1007/s10984-021-09377-8\n\n\nCai, Z., Fan, X., & Du, J. (2017). Gender and attitudes toward technology use: A meta-analysis. Computers & Education, 105, 1–13. https://doi.org/10.1016/j.compedu.2016.11.003\n\n\nCampos, D. G., & Scherer, R. (2024). Digital gender gaps in Students’ knowledge, attitudes and skills: An integrative data analysis across 32 Countries. Education and Information Technologies, 29(1), 655–693. https://doi.org/10.1007/s10639-023-12272-9\n\n\nChen, X., & Hu, J. (2020). ICT-related behavioral factors mediate the relationship between adolescents’ ICT interest and their ICT self-efficacy: Evidence from 30 countries. Computers & Education, 159, 104004. https://doi.org/10.1016/j.compedu.2020.104004\n\n\nChikezie, C. (2024). Measuring the impact of socioeconomic status related traits on technology usage : two validated surveys. Oregon State University.\n\n\nEastin, M. S., & LaRose, R. (2000). Internet Self-Efficacy and the Psychology of the Digital Divide. Journal of Computer-Mediated Communication, 6(1), JCMC611. https://doi.org/10.1111/j.1083-6101.2000.tb00110.x\n\n\nGebhardt, E., Thomson, S., Ainley, J., & Hillman, K. (2019). Student Achievement and Beliefs Related to Computer and Information Literacy. In E. Gebhardt, S. Thomson, J. Ainley, & K. Hillman (Eds.), Gender Differences in Computer and Information Literacy: An In-depth Analysis of Data from ICILS (pp. 21–31). Springer International Publishing. https://doi.org/10.1007/978-3-030-26203-7_3\n\n\nHammer, M., Scheiter, K., & Stürmer, K. (2021). New technology, new role of parents: How parents’ beliefs and behavior affect students’ digital media self-efficacy. Computers in Human Behavior, 116, 106642. https://doi.org/10.1016/j.chb.2020.106642\n\n\nHatlevik, O. E., Throndsen, I., Loi, M., & Gudmundsdottir, G. B. (2018b). Students’ ICT self-efficacy and computer and information literacy: Determinants and relationships. Computers & Education, 118, 107–119. https://doi.org/10.1016/j.compedu.2017.11.011\n\n\nHatlevik, O. E., Throndsen, I., Loi, M., & Gudmundsdottir, G. B. (2018a). Students’ ICT self-efficacy and computer and information literacy: Determinants and relationships. Computers & Education, 118, 107–119. https://doi.org/10.1016/j.compedu.2017.11.011\n\n\nHori, R., & Fujii, M. (2021). Impact of Using ICT for Learning Purposes on Self-Efficacy and Persistence: Evidence from Pisa 2018. Sustainability, 13(11), 6463. https://doi.org/10.3390/su13116463\n\n\nJuhaňák, L., Zounek, J., Záleská, K., Bárta, O., & Vlčková, K. (2019). The relationship between the age at first computer use and students’ perceived competence and autonomy in ICT usage: A mediation analysis. Computers & Education, 141, 103614. https://doi.org/10.1016/j.compedu.2019.103614\n\n\nLai, X., Nie, C., Huang, S., Yao, Y., Li, Y., Dai, X., & Wang, Y. (2022). Classes of problematic smartphone use and information and communication technology (ICT) self-efficacy. Journal of Applied Developmental Psychology, 83, 101481. https://doi.org/10.1016/j.appdev.2022.101481\n\n\nScherer, R., & Siddiq, F. (2015). Revisiting teachers’ computer self-efficacy: A differentiated view on gender differences. Computers in Human Behavior, 53, 48–57. https://doi.org/10.1016/j.chb.2015.06.038\n\n\nSenkbeil, M. (2023). How well does the digital home learning environment predict ICT literacy and ICT self-efficacy? Comparing the predictive power of adolescent and parent reports. Computers & Education, 207, 104937. https://doi.org/10.1016/j.compedu.2023.104937\n\n\nStone, J. A. (2020). ICT Self-Efficacy: Gender and Socioeconomic Influences Among First-Year Students. International Journal of Gender, Science and Technology, 12(3), 377–394.\n\n\nZhong, Z.-J. (2011). From access to usage: The divide of self-reported digital skills among adolescents. Computers & Education, 56(3), 736–746. https://doi.org/10.1016/j.compedu.2010.10.016",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Digital Self-efficacy Divide</span>"
    ]
  },
  {
    "objectID": "10_digital_selfeff_divide.html",
    "href": "10_digital_selfeff_divide.html",
    "title": "9  Digital Self-efficacy Divide",
    "section": "",
    "text": "9.1 First Self-efficacy divide: access\nAccess is positioned as a crucial variable for Digital Self-Efficacy (DSE), as it represents the first element of the digital divide problematized in academic studies. Recent literature highlights a positive relationship between greater access to technology and higher levels of DSE. Stone (2020) identifies a significant relationship between increased access to ICT and greater self-efficacy in the domains of basic computing, internet use, applications, and content creation. Previous studies have also documented this relationship (Tondeur, Sinnaee, Van Houtte, & Van Braak, 2011, as cited in Hatlevik et al. (2018a); Aesaert & Van Braak, 2014; Tsai & Tsai, 2010; Zhong, 2011, as cited in Senkbeil (2023)).\nDue to the simplicity of the dichotomy between access and lack of access to technology, multiple dimensions of access disparities to ICT have been proposed. A study by Ball et al. (2020) examines how these various dimensions relate to DSE, dividing it into Technology Self-Efficacy (TSE) and Application Self-Efficacy (ASE). Among the key findings, a significant relationship was observed between access to and use of computers at home and TSE; however, no such relationship was found with ASE.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Digital Self-efficacy Divide</span>"
    ]
  },
  {
    "objectID": "09_digital_divide_framework.html",
    "href": "09_digital_divide_framework.html",
    "title": "8  Digital Divide Framework",
    "section": "",
    "text": "8.1 Digital divide framework\nIn this section, the ideas of Lythreatis et al. (2022) related to the concept of digital divide will be summarized. This is relevant to address since it provides us with a conceptual framework and bibliography to understand the digital inequalities, potentially addressed in this agenda. This chapter may potentially be expanded to include a more extensive historical overview of the concept, as well as the various approaches, criticisms, and proposals related to it.\nThe concept of the digital divide, coined by scholars during the 1990s, refers to the various gaps in access, usage, and outcomes associated with Information and Communication Technologies (ICT). The digital divide has gained increasing prominence due to the rise of the digital economy; the concept has been embraced by numerous organizations and public policy institutions. For instance, the United Nations places significant emphasis on ICT as a means to achieve its Sustainable Development Goals (SDGs) and combat social inequalities. The significance of the concept lies not only in its impact on individuals’ relationships with the digital world but also in its implications for social mobility, given the pervasive integration of ICT into both the labor market and educational systems. Three levels or grades of the digital divide have been proposed, each with its specific characteristics and context.\nThe first level to emerge was the most restrictive, focusing solely on disparities in ICT access within the population. This was conceptualized simply as a dichotomy between those with effective access to technology and those without.\nAt the dawn of the new millennium, scholars recognized the need to broaden the concept, as access disparities alone failed to capture the growing inequalities tied to technology and digitalization. The second level of the digital divide encompasses differences in access to relevant content, the quality of connectivity, digital knowledge and skills, attitudes, behaviors, and emotions.\nA third level of the digital divide was proposed as a critique of the assumption that equal access and use of ICT would necessarily yield equal outcomes. Consequently, it became essential to examine the benefits or consequences derived from ICT usage.\nThe concept of the digital divide has been studied through various approaches and a wide range of variables. As a result, it has been proposed to conceptualize it as a multidimensional and dynamic phenomenon, aligned with the rapid pace of technological change in contemporary society.\nThe most relevant determinants of the digital divide include age, gender, socioeconomic status, attitudes, beliefs, emotions, ICT experience and training, rights, infrastructure, and large-scale events (e.g., COVID-19).\nMoreover, recent literature has proposed new levels of the digital divide. Bartikowski et al. (2018, cited in Lythreatis et al. (2022)) argued that the type of internet use is a critical component of the digital divide. Cinamon (2020, cited in Lythreatis et al. (2022)) highlighted data inequalities as a significant but insufficiently addressed aspect of the digital divide. Gran et al. (2021, cited in Lythreatis et al. (2022)) introduced a new fourth level of the digital divide, which examines the positive and negative effects of algorithms on individuals. Awareness of and access to information about algorithms could become a crucial societal issue, particularly as algorithms assume a significant role in public participation, posing a challenge to democracy.\nIntegrating this research agenda into the broader literature on the digital divide is essential. Self-efficacy aligns with the second level of the digital divide but is also proposed as a significant predictor of digital skills, directly linked to the outcomes individuals can achieve through digital technologies. Additionally, the Digital Self-Efficacy (DSE) research agenda aims to explore potential gender differences and their relationship with countries’ levels of development—a focus that aligns closely with studies on the digital divide. As a mechanism for personal reflection, self-efficacy has a strong connection with learning (and therefore with literacy and skills), particularly in today’s context of accelerated technological change, which encourages the constant acquisition of new skills. Additionally, technology-related self-efficacy is related to Internet use and adoption, presenting itself as an alternative explication of the digital divide to the classic socioeconomic reasons [Eastin & LaRose (2000)]. High self-efficacy enables individuals to adapt to the dynamic labor and educational environments and to independently learn the knowledge required by current circumstances.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Digital Divide Framework</span>"
    ]
  },
  {
    "objectID": "11_next_agenda.html",
    "href": "11_next_agenda.html",
    "title": "10  Bandura’s Self-efficacy concept: aplications and measurements",
    "section": "",
    "text": "10.1 Methods studying Digital Self-Efficacy differences\nAs a concluding chapter, it is essential to project methodologies and knowledge gaps that directly influence the DSE agenda of NUDOS. In the first subsection, the measurement and application of Bandura’s self-efficacy concept in research are critically examined. Next, the main methodologies used in the reviewed studies are analyzed, with a particular focus on multilevel studies incorporating country-level data and International Large-Scale Assessments (ILSA). Finally, the chapter addresses the knowledge gaps surrounding the determinants of DSE.\nThroughout the literature review, a multitude of methodological tools have been identified as useful for the DSE agenda of NUDOS. The vast majority of the studies reviewed involve multilevel models and, at times, structural equation modeling, due to the availability of school-level data in ILSAs and the effort to explore mediators of relationships already demonstrated in the literature. Additionally, periodic meta-analyses that synthesize findings from previous research are evident.\nThe study by Hatlevik et al. (2018), the most relevant one with ICT self-efficacy as the dependent variable, conducts a path analysis, a multivariate model that allows the inclusion of multiple independent and dependent variables simultaneously. It seeks to identify the main determinants of ICT self-efficacy and, additionally, the relationship between digital literacy and digital self-efficacy, using ICILS 2013 data. The analysis included 14 countries. For the reporting of results, the range of effects across all countries was mentioned, with occasional emphasis on outlier cases.\nThe article by Chen & Hu (2020) is particularly relevant to the agenda because it uses PISA data, encompassing a large number of countries (30). The study conducts a multilevel mediation model (utilizing the school level) that does not account for relationships between mediators, assuming instead that they do not covary. The independent variable is interest in ICT, the dependent variable is ICT self-efficacy, and the mediating variables considered were ICT use at home for leisure, ICT use at home for school tasks, ICT use for socializing, and ICT use in school. Additionally, gender and the index of economic, social, and cultural status (ESCS)—the latter being readily available in the PISA database—were included as control variables. The chosen technique for mediation analysis was the parallel multiple mediator model, which allows for the inclusion of multiple mediating variables in the analysis simultaneously. Similar to Hatlevik’s article, the range of effects across the different countries was reported.\nThe paper by Campos & Scherer (2024) may serve as an excellent roadmap for research on PISA 2022. It conducts a meta-analysis combining data from ICILS 2013, ICILS 2018, and findings from 165 different articles sourced from databases (ERIC and PsycINFO). The study’s objective is to determine the extent to which gender differences in digital skills are mediated by attitudes, analyzing heterogeneity across countries and studies. Missing data were imputed through a two-level mean-matching approach (considering background data, technology use, and attitudes toward technology), resulting in 100 datasets for each ICILS cycle. Beyond this, and of particular relevance to the Digital Self-Efficacy agenda, a variety of indices were used to explore relationships between country-level outcomes and socioeconomic development, gender inequality, and other factors. Specifically, the following indices were employed: Human Development Index, Gender Inequality Index, Global Innovation Index, and ICT Use Index. Additionally, UNESCO’s country classification was used. In total, four distinct models were executed for each attitude addressed in the study (self-efficacy, beliefs, and affect). The first was a multivariate model with simple random effects; the second was a multilevel model adding the country variable; the third was a multilevel, multivariate model capturing the average effects of direct and indirect variables and their variance at different levels; and the fourth added the aforementioned indices to the first model.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bandura's Self-efficacy concept: aplications and measurements</span>"
    ]
  },
  {
    "objectID": "11_next_agenda.html#knowledge-gaps-regarding-digital-self-efficacy",
    "href": "11_next_agenda.html#knowledge-gaps-regarding-digital-self-efficacy",
    "title": "10  Bandura’s Self-efficacy concept: aplications and measurements",
    "section": "10.2 Knowledge gaps regarding Digital Self-efficacy",
    "text": "10.2 Knowledge gaps regarding Digital Self-efficacy\nThe relationship between various socioeconomic, sociodemographic, and subjective variables and technology-related self-efficacy has been studied. However, there is still a need to examine diverse relationships and profiles of technology users who, to this day, are being left behind in the face of the burgeoning technological revolution. One of the most notable gaps is the lack of studies considering migration background or ethnicity as an independent variable. In other fields of study, this has been addressed; for example, a study conducted in Chile found a positive relationship between students’ migrant status and their general self-efficacy (cespedesRelationshipSelfConceptSelfEfficacy2021?). It is crucial to examine this relationship in the context of digital self-efficacy, as digital competencies have become vital for adapting to a new country and achieving economic advancement.\nSimilarly, there is a noticeable lack of studies that delve into explaining differences in ICT self-efficacy across the various countries that have participated in ILSAs. Although articles such as Campos & Scherer (2024) incorporate indices like the Human Development Index and the ICT Use Index, they do not use digital self-efficacy as the dependent variable, and analyzing the role of the country in the development of a particular technological self-efficacy is far from being their primary objective. This issue is particularly relevant when addressing the digital divide in its broadest dimension: the global one.\n\n\n\n\nCampos, D. G., & Scherer, R. (2024). Digital gender gaps in Students’ knowledge, attitudes and skills: An integrative data analysis across 32 Countries. Education and Information Technologies, 29(1), 655–693. https://doi.org/10.1007/s10639-023-12272-9\n\n\nChen, X., & Hu, J. (2020). ICT-related behavioral factors mediate the relationship between adolescents’ ICT interest and their ICT self-efficacy: Evidence from 30 countries. Computers & Education, 159, 104004. https://doi.org/10.1016/j.compedu.2020.104004\n\n\nHatlevik, O. E., Throndsen, I., Loi, M., & Gudmundsdottir, G. B. (2018). Students’ ICT self-efficacy and computer and information literacy: Determinants and relationships. Computers & Education, 118, 107–119. https://doi.org/10.1016/j.compedu.2017.11.011",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bandura's Self-efficacy concept: aplications and measurements</span>"
    ]
  },
  {
    "objectID": "07_icils_timss_pisa.html",
    "href": "07_icils_timss_pisa.html",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "",
    "text": "6.1 About ICILS, TIMSS and PISA\nWithin ILSAs, there are two major organizations that have promoted this type of study: the IEA and the OECD. On the one hand, the IEA is the association in charge of leading and conducting two of the most important large-scale assessment studies: International Computer and Information Literacy Study 1 and Trends in International Mathematics and Science Study 2. On the other hand, the OECD is the orchestrator of the Programme for International Student Assessment 3, one of the leading ILSAs in the world. These three studies share the same target population in that they focus on adolescents, specifically young people between the ages of 13 and 15. More importantly, all of the aforementioned studies contain a digital self-efficacy battery, so the following paragraphs will seek to describe at a general level each of the ILSAs, and then to show how they address digital self-efficacy in their evaluative frameworks. Subsequently, a comparative analysis will be made between the digital self-efficacy batteries between cycles of the same study, as well as between different studies, to finally propose a discussion on the successes and failures in the different measurements that have been proposed regarding digital self-efficacy.\nICILS is a study on digital literacy, which seeks to answer the question: How well are students prepared to study, work and live in a digital world? To this end, the study measures achievement in computer and information literacy (CIL), a concept defined as “an individual’s ability to use computers to investigate, create, and communicate in order to participate effectively at home, at school, in the workplace, and in society” (Julian Fraillon et al., 2013, p. 17). It is worth mentioning that this concept is operationalized by ICILS in order to measure digital literacy. The study deploys a complex sample design involving multistage, stratified and cluster sampling techniques (see p.59, Julian Fraillon et al., 2020).\nThe first ICILS study cycle was conducted in 2013. It involved 22 educational systems, and was the inaugural milestone of the study that seeks to measure achievement in CIL see on official website. Subsequently, the second cycle of the study occupied 2018, covering only 13 countries, but Computational Thinking domain was added as one of the key aspects to be studied. Currently, the report of the results of the third cycle of the study was recently published, which was conducted in 2023, while the databases will be officially released in March of this year.\nThe second study to be analyzed in this paper is TIMSS, which is conducted by the IEA and PIRLS International Study Center at Boston College’s Lynch School of Education and Human Development. This ILSA, as its name implies, focuses on assessing the performance of fourth and eighth grade students in mathematics and science. In addition, it contains questions related to the students’ context.\nThe first TIMSS study was carried out in 1995 and has been conducted periodically every 4 years without fail. Regarding the most recent cycles, it is worth mentioning that TIMMS 2019 was attended by 72 educational systems, while the subsequent cycle carried out in 2023 repeated the same number of participants see on official website. The results of the eighth and final cycle of the study have recently been published, and the next cycle, which is scheduled for 2027, is already in sight. It is important to mention that the sample design of this study is based on a two-stage stratified random sampling, with the sample of schools as the first stage and the selection of the classes of students in each school as the second stage (see p. 3.1, Siegel, P. & Foy, P., 2024)\nRegarding the approach to technology in their questionnaires, in the 2011 cycle we found for the first time the presence of questions on this topic, although they only referred to the frequency of computer use at home and at school.\nFinally, there is PISA, a study that is organized and executed by the OECD. PISA is characterized by measuring the abilities of 15-year-old adolescents to use their knowledge in reading, mathematics and science to face challenges in real life. This ILSA stands out for the great thematic versatility of its questionnaires. For example, the 2022 cycle contained 7 surveys, which dealt with topics such as financial literacy or good living. In addition, in each cycle of the study, one domain area takes center stage. Particularly, in 2018, the area of reading predominated, while the 2022 study focused especially on the mathematical area.\nPISA originated in 2000, and since that year the study has been carried out periodically every 3 years. The only cycles that escape this rule are those of 2022 and 2025 (next to be carried out), since the pandemic and the subsequent cancellation of face-to-face classes prevented the surveys from being duly deployed in 2021. For this reason, the eighth cycle of PISA (2021 initially) was postponed to the following year, consequently affecting the date of the subsequent cycle. A noteworthy aspect is that since the first PISA cycle, space has been given to familiarity with technology.\nThis study implements a two-stage stratified sample design. The first stage were schools that had 15-year-old students to be surveyed, as the second sampling units were the students within sampled schools (see p. 104, OECD, 2024). In terms of participation levels in the latest studies, the cycle conducted in 2018 had 79 countries and economies, while the study conducted in 2022 was made up of 81 participants. Both cycles included OECD and non-OECD members.\nA striking aspect of PISA is that from the beginning of the study they have contemplated a questionnaire on familiarity with technology. Due to rapid technological transformations, this questionnaire has undergone constant modifications. Nevertheless, digital self-efficacy appears as an inconsistent item in the different PISA cycles. In both 2000 and 2009 digital self-efficacy is absent in the questionnaires, however, in all other cycles it is present.\nEach study has extensive documentation that is open access, which can be found on their respective web pages. There, the implemented questionnaires, technical reports, databases, among other files, can be viewed and downloaded. The openness of their data is of great value, since it allows them to be analyzed in order to generate knowledge in various fields, such as academia or public policy.\nSimilarly, it is extremely important to clarify that both TIMMS and PISA use characterization questionnaires as the only resource to address digital issues, which, ultimately, does not allow measuring the competencies or skills of respondents. Not so ICILS, which, in addition to covering characterization elements, deploys a standardized performance assessment test, which has the objective that digital literacy can be measured in a concrete way.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy</span>"
    ]
  },
  {
    "objectID": "07_icils_timss_pisa.html#how-this-studies-adress-digital-self-efficacy",
    "href": "07_icils_timss_pisa.html#how-this-studies-adress-digital-self-efficacy",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "6.2 How this studies adress Digital self-efficacy?",
    "text": "6.2 How this studies adress Digital self-efficacy?\nICILS, being focused on digital issues, does not have a specific section of the document dealing with it, but the document is framed in this topic. However, the evaluation framework of this study contains a chapter focused on contextual determinants, which is subdivided into the types of context that influence computer and information literacy, such as home context, school context, and individual context. The latter includes attitudinal and behavioral factors. Self-efficacy is placed in this framework.\nTo conceptualize self-efficacy, the study paraphrases Bandura’s (1993) definition, stating that self-efficacy is students’ confidence in their own ability to perform tasks in a specific area (Bandura, 1993, as cited in Julian Fraillon et al., 2013). In this way, it is made explicit that the questionnaire aims to measure the confidence expressed by students when performing ICT-related tasks. In this sense, ICILS employs the concept of ICT self-efficacy. In addition, the previous wave of the study is mentioned, emphasizing the identification of two dimensions of self-efficacy: basic and advanced. In this study, they will continue with this distinction. Finally, literature is presented that supports the idea that self-efficacy is a relevant variable for predicting achievement, in this case, in computational and information literacy (see p. 41, Fraillon et al., 2019).\nPISA has an ICT assessment framework, which considers 3 dimensions: ICT uses; ICT access and ICT competencies of students. The latter specifies the most relevant competencies identified in existing assessment frameworks on digital literacy. It is worth mentioning that the framework provided by PISA goes in the direction of laying the foundations for, in the future, being able to integrate ICT literacy as a specific domain in its study. Therefore, the document defines ICT literacy as “the interest, attitude and ability of individuals to appropriately use digital technologies and communication tools to access, manage, integrate and evaluate information, construct new knowledge, and communicate with others in order to participate effectively in society” (Lenon et al., 2003, as cited in OECD, 2023). This definition is not original to PISA, but resorts to the conceptualization of Lenon et al. (2003).\nICT competencies include knowledge, understanding, attitudes, dispositions and skills. Self-efficacy is among the attitudes and dispositions towards ICT. In greater depth, the 5 main areas of ICT competencies are: accessing, managing and evaluating information and data (1); sharing information and communicating (2); transforming and creating digital content (3); individual and collaborative problem solving in digital contexts, and computational thinking (4); appropriate use of ICT (knowledge and skills related to safety, security and risk awareness) (5). In this context, it is made explicit that the measure of self-efficacy is the main assessment instrument for ICT competencies.\nIt is worth mentioning that PISA does not explicitly define “digital self-efficacy” but treats self-efficacy throughout the document in the framework of attitudes and dispositions towards ICT, so that a specific concept of self-efficacy is absent (see p. 277, OECD, 2023).\nTIMMS is the study with the least extensive evaluation framework on digital issues, so it can be assumed that it is not a section that has been prioritized in the questionnaire. Instead, information on student performance in mathematics and science prevails.\nThe TIMMS cycle conducted in 2019 conceptualizes self-efficacy as “Student confidence using technology”, being considered in the section “Student attitudes toward learning”, where student attitudes toward mathematics and science are also highlighted (see pp. 72, Ina V.S. Mulllis & Michael O. Martin, 2019). Subsequently, in the 2023 cycle of the same study, the concept is changed to “digital self-efficacy”, which is framed in the section “Information technologies and digital services”. In it, two variables are specified: uses of digital services (1) and digital self-efficacy (2). In neither of the two cycles is there a previous contextualization that supports the presentation of these topics, nor a deep justification of why self-efficacy in digital issues is relevant. Nor is there a conceptualization of self-efficacy as such. Despite all these gaps, the study does employ a specific concept in both of its two cycles (see p. 59, Ina V.S. Mulllis et al., 2023).\nDespite the lack of theoretical depth regarding digital self-efficacy, one of the most interesting features of TIMMS is that in addition to containing the digital self-efficacy battery, it has self-efficacy batteries for mathematics and science, which could open certain lines of research regarding this specific topic.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy</span>"
    ]
  },
  {
    "objectID": "07_icils_timss_pisa.html#measures-of-digital-self-efficacy",
    "href": "07_icils_timss_pisa.html#measures-of-digital-self-efficacy",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "6.3 Measures of digital self-efficacy",
    "text": "6.3 Measures of digital self-efficacy\n\n\nWarning: package 'kableExtra' was built under R version 4.3.3\n\n\nWarning: package 'openxlsx' was built under R version 4.3.3\n\n\n\n\n\n\nEstudios\nICILS.2013\nICILS.2018\nPISA.2018\nPISA.2022\nTIMSS.2019\nTIMSS.2023\n\n\n\n\nConcepto específico\nICT Self-efficacy\nICT Self-efficacy\nSelf-efficacy\nSelf-efficacy\nStudent confidence using technology\nDigital self-efficacy\n\n\nCantidad de dimensiones\n2\n2\n1\n1\n1\n1\n\n\nTipos de dimensiones\nBásica y avanzada\nGeneral y especializada\nGeneral\nGeneral\nGeneral\nGeneral\n\n\nFraseo del ítem\nHow well can you do each of these tasks on a computer?\nHow well can you do each of these tasks on a computer?\nThinking about your experience with digital media and digital devices: to what extent do you disagree or agree with the following statements?\nTo what extent are you able to do the following tasks when using &lt;digital devices&gt;?\nHow much do you agree with these statements?\nHow much do you agree with these statements?\n\n\nÍtems que componen la batería\nBásica\nGeneral\nGeneral\nGeneral\nGeneral\nGeneral\n\n\nÍtems que componen la batería\n1) Search for and find a file on your computer\n1) Edit digital photographs or other graphics images\n1) I feel comfortable using digital devices that I am less familiar with\n1) Search for and find relevant information online\n1) I am good at using a computer\n1)I can write and edit text on a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n2) Edit digital photographs or other graphic images\n2) Write or edit a text for a school assignment\n2) If my friends and relatives want to buy new digital devices or applications, I can give them advice\n2) Asses the quality of information you found online\n2) I am good at typing\n2)I can create school presentations using a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n3) Create or edit documents (for example assignments for school)\n3) Search for and find relevant information for a school project on Internet\n3) I feel comfortable using digital devices at home\n3) Share practical information with a group of students\n3) I can use a touchscreen on a computer, tablet or smartphone\n3)I can create, tables, charts and graphs using a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n4) Search for and find information you need on the Internet\n4) Create a multimedia presentation (with sound, pictures, or video)\n4) When I come across problems digital devices, I think I can solve them\n4) Collaborate with other students on a group assesment\n4) It is easy for me to find information on the Internet\n4)I can find information that I need online\n\n\nÍtems que componen la batería\n5) Create a multi-media presentation (with sound, pictures, or video)\n5) Upload text, images, or video to an online profile\n5) If my friends and relatives have a problem with digital devices, I can help them\n5) Explain to other students how to share digital content online on or a school platform\n5) I can look up the meanings of words on Internet\n5)I can tell if a website is trustworthy\n\n\nÍtems que componen la batería\n6) Upload text, images or video to an online profile\n6) Insert an image nto a document or message\n6) If I need new softare, I install it by myself\n6) Write or edit text for a school assignment\n6) I can write sentences and paragraphs using a computer\n6)I can easily do new things on computers, laptops or smartphones\n\n\nÍtems que componen la batería\n\n7) Install a program or [app]\n7) I read information about digital devices to be independent\n7) Collect and record data (e.g. using data loggers, &lt;Microsoft Access&gt;, &lt;Google form&gt;, spreadsheets)\n7) I can edit on a computer\n7)I can help my friends or family members with using their computers, laptops and smartphones\n\n\nÍtems que componen la batería\n\n8) Judge whether you can trust information you find on internet\n8) I use digital devices as I want to use them\n8) Create a multimedia presentation (with sound, pictures and video)\n\n\n\n\nÍtems que componen la batería\n\n\n9) If I have a problem with digital devices I start to solve it on my own\n9) Create, update and mantain a webpage or blog\n\n\n\n\nÍtems que componen la batería\n\n\n10) If I need a new application, I choose it by myself\n10) Change the setting of a device or app in order to protect my data and privacy\n\n\n\n\nÍtems que componen la batería\n\n\n\n11) Select the most efficient programme or app that allows me to carry out a specific task\n\n\n\n\nÍtems que componen la batería\n\n\n\n12) Create a computer program (e.g. in &lt;Scratch&gt;, &lt;Python&gt;, &lt;Java&gt;)\n\n\n\n\nÍtems que componen la batería\n\n\n\n13) Identify the source of an error in a software afeter considering a list of potential causes\n\n\n\n\nÍtems que componen la batería\nAvanzada\nEspecializada\n\n\n\n\n\n\nÍtems que componen la batería\n1) Use software to find and get rid of viruses\n1)Create a database (e.g., using [Microsoft Access])\n\n\n\n\n\n\nÍtems que componen la batería\n2) Create a database (for example using [Microsoft Access])\n2)Build or edit a webpage\n\n\n\n\n\n\nÍtems que componen la batería\n3) Build or edit a webpage\n3)Create a computer program, or [app] (e.g., in [Basic, Visual Basic])\n\n\n\n\n\n\nÍtems que componen la batería\n4) Change the settings on your computer to improve the way it operates or to fix problems\n4)Set up a local area network of computers or other ICT\n\n\n\n\n\n\nÍtems que componen la batería\n5) Use a spreadsheet to do calculations, store data or plot a graph\n\n\n\n\n\n\n\n\n6) Create a computer program or macro (for example in [Basic, Visual Basic])\n\n\n\n\n\n\n\n\n7) Set up a computer network\n\n\n\n\n\n\n\nCategorías de respuesta\nI know how to do this (1); I could work out how to do this (2); I do not think I could do this (3)\nI know how to do this (1); I could work out how to do this (2); I do not think I could do this (3)\nStrongly disagree (1); Disagree (2); Agree (3); Strongly agree (4)\nI cannot do this (1), I struggle to do this on my own (2), I can do with a bit of effort (3), i can easily do this (4), I don´t know what this is (5)\nAgree a lot (1); Agree a little (2); Disagree a little (3); Disagree a lot (4)\nAgree a lot (1); Agree a little (2); Disagree a little (3); Disagree a lot (4)\n\n\nDiferencias entre ciclo\nDimensiones de autoeficacia Enunciados de las baterías\nDimensiones de autoeficacia Enunciados de las baterías\nFraseo del ítem Enunciados de las baterías Categorías de respuesta\nFraseo del ítem Enunciados de las baterías Categorías de respuesta\nConcepto de autoeficacia Enunciados de las baterías\nConcepto de autoeficacia Enunciados de las baterías\n\n\n\n\n\n\n\nTable 3 shows the digital self-efficacy batteries belonging to the last two cycles of each study mentioned above, including some of their characteristics such as item phrasing and/or response categories. This was done in order to illustrate the differences that exist between the different cycles of a study, as well as the differences between studies.\nFirstly, in ICILS, it can be observed that the specific concept with which they deal with digital self-efficacy has been maintained, using “ICT Self-efficacy” in its two cycles. Likewise, both the item phrasing and the response categories that were proposed in the first cycle of the study remained unchanged in the second cycle.\nOn the contrary, the change in the conceptualization of the type of ICT self-efficacy dimensions stands out, since, while in the 2013 cycle they were defined as “basic and advanced”, in the 2018 cycle this was modified to “general and specialized”. Now, the most significant change is in the items that make up the ICT Self-efficacy batteries in the two cycles. In the basic-general dimension, for the 2013 cycle there are 6 items, finding a tendency towards digital editing and searching tasks, while in the 2018 cycle there are 8 items in total, including topics of program installation and information evaluation. On the other hand, in the advanced-specialized dimension there is a decrease of items when comparing the first and second cycle. In 2013 this battery was made up of 7 items, and in 2018 only 4, leaving aside tasks such as removing viruses from a computer or using spreadsheets.\nThe digital-themed self-efficacy batteries in PISA change almost all of their characteristics from one cycle to the next, only keeping the understanding of self-efficacy on a single dimension. First, the item phrasing in the 2018 cycle attends to the extent to which the respondent agrees or disagrees with the statements to be presented. In contrast, in the 2022 cycle it refers to the extent to which the respondent is able to perform the tasks that will be presented. These changes in the phrasing of the item also have implications for the response categories of the cycles, since they point to different questions. For the 2018 cycle the responses are based on a scale ranging from “strongly disagree” to “strongly agree,” while the response categories for the last cycle range from “I cannot do it” to “I can do it easily.”\nThe items of the PISA batteries also underwent several changes. First, the 2022 cycle has 3 more items compared to the 2018 cycle. To elaborate on this, the items of the first cycle of this study are mainly made up of statements that allude to the feeling of comfort with the use of digital services, as well as tasks that point to autonomy in the digital sphere. In contrast, the 2022 items focus on task performance, including skills ranging from practical knowledge to critical evaluation. In addition, it can be generally noted that the battery is constructed in such a way that the first items point to tasks that do not demand great complexity, while the last items require much more in-depth knowledge and skills in the digital domain.\nThe measurement of digital self-efficacy in TIMSS has maintained certain characteristics, specifically the consideration of a single self-efficacy dimension, item phrasing and subsequent response categories. The question that supports this battery expresses the degree to which one agrees with the statements, so the response categories range from “strongly agree” to “strongly disagree”.\nNow, the concept with which self-efficacy in digital subjects is treated is different between the two TIMMS cycles. For the 2019 cycle the concept “Student confidence using techonology” was used, which in the 2023 cycle would change to “Digital Self-efficacy”.\nAnother aspect that underwent modifications was the construction of the digital self-efficacy batteries. In the previous cycle, the battery consisted of 7 items, which focused on practical tasks of a low level of complexity; among them, “being good at typing” or “being able to use a touchscreen”. In TIMSS 2023, the same number of items are observed, but they address tasks that require greater knowledge in the field, such as creating presentations or graphics, or feeling able to help others in the use of digital services.\nBetween ICILS, PISA and TIMSS, major differences can be noted in terms of the characteristics of their self-efficacy batteries in the digital domain. First, TIMSS is the only study that has modified the conceptualization of self-efficacy in relation to technology. However, ICILS stands out for comprising two dimensions of digital self-efficacy, whereas the other studies only take into account one generalized dimension. On the other hand, the item phrasings and the response categories derived from them differ between each study. The closest studies in these measurement characteristics are PISA 2018 with the two TIMMS cycles when measuring the degree of agreement.\nThe greatest differences are found in the items that make up the digital self-efficacy batteries. Each study has undergone transformations in the items that make up the batteries, some including a greater number of statements, or adding tasks of greater complexity and omitting aspects that were measured in their respective previous cycles.\nThis section conducted a comparative analysis of the construction of the digital self-efficacy batteries, observing the items that constitute such batteries in the different cycles of the different studies, as well as the differences presented intra-cycle and intra-study. The next section seeks to deepen the analysis of how self-efficacy in digital issues has been measured in the studies presented in the document, through an evaluation based on the conceptual framework provided by Bandura, which was presented in the first part of this working paper.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy</span>"
    ]
  },
  {
    "objectID": "07_icils_timss_pisa.html#references",
    "href": "07_icils_timss_pisa.html#references",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "References",
    "text": "References\n\n\n\n\nFraillon, J., Ainley, J., Schulz, W., Duckworth, D., & Friedman, T. (2019). Contextual framework. In IEA International Computer and Information Literacy Study 2018 Assessment Framework (pp. 33–42). Springer International Publishing. https://doi.org/10.1007/978-3-030-19389-8_4\n\n\nIna V.S. Mulllis, & Michael O. Martin. (2019). TIMSS 2019 Context Questionnaire Framework. In TIMSS 2019 Assessment Frameworks. TIMSS & PIRLS International Study Center, Lynch School of Education, Boston College and International Association for the Evaluation of Educational Achievement (IEA).\n\n\nIna V.S. Mulllis, Michael O. Martin, & Matthias von Davier. (2023). TIMSS 2023 Context Questionnaire Framework. In TIMSS 2023 Assessment Frameworks. TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College and International Association for the Evaluation of Educational Achievement (IEA).\n\n\nJulian Fraillon, John Ainley, Wolfram Schulz, Tim Friedman, & Daniel Duckworth. (2020). Sample design and implementation. In IEA International Computer and Information Literacy Study 2018 Technical Report. International Association for the Evaluation of Educational Achievement (IEA).\n\n\nJulian Fraillon, Wolfram Schulz, & John Ainley. (2013). IEA International Computer and Information Literacy Study 2013 Assessment Framework. International Association for the Evaluation of Educational Achievement (IEA).\n\n\nOECD. (2023). PISA 2022 ICT Framework. In PISA 2022 Assessment and Analytical Framework (pp. 238–285). OECD Publishing.\n\n\nOECD. (2024). PISA 2022 Technical Report. OECD Publishing.\n\n\nSiegel, P., & Foy, P. (2024). TIMSS sample design. In TIMSS 2023 Technical Report (Methods and Procedures) (pp. 3.1–3.30). Boston College, TIMSS & PIRLS International Study Center.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy</span>"
    ]
  },
  {
    "objectID": "07_icils_timss_pisa.html#footnotes",
    "href": "07_icils_timss_pisa.html#footnotes",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "",
    "text": "Hereinafter, ICILS↩︎\nHereinafter, TIMSS↩︎\nHereinafter, PISA↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy</span>"
    ]
  },
  {
    "objectID": "06_ilsa.html",
    "href": "06_ilsa.html",
=======
    "objectID": "06_ilsa.html#why-to-work-with-international-large-scale-assesments",
    "href": "06_ilsa.html#why-to-work-with-international-large-scale-assesments",
>>>>>>> Stashed changes
=======
    "objectID": "06_ilsa.html#why-to-work-with-international-large-scale-assesments",
    "href": "06_ilsa.html#why-to-work-with-international-large-scale-assesments",
>>>>>>> Stashed changes
    "title": "5  International Large-Scale Asessments and Digital Issues",
    "section": "5.1 Why to work with International Large-Scale Assesments?",
    "text": "5.1 Why to work with International Large-Scale Assesments?\nThe digital self-efficacy agenda that has opened up with these discussions has presented different approaches. On the one hand, it has diversified into case studies or small-scale comparative research. On the other hand, there are antecedents that deal with the problem from experiments and qualitative techniques. However, the largest dossier on this agenda is found in large-scale educational issues studies with a survey approach.\nIn recent years, International Large-scale Assessments1 have become one of the most relevant types of studies in the field of education, thanks to the large amount of data they collect, the versatility in how the data can be treated, and, consequently, the diverse contributions they can provide to the regions.\nThe birth of ILSA dates to 1958, when a group of researchers at the UNESCO Institute of Education were very interested in studying educational achievement and its determinants in different countries, intending to enable countries to learn from the experience of others and thus avoid decisions that would produce undesirable results (husenInternationalResearchVenture1979?). This led to the creation of the International Association for the Evaluation of Educational Achievement2. Since then, the IEA has conducted ILSAs periodically. Likewise, the Organization for Economic Cooperation and Development 3 has also been a highly relevant organization in promoting the implementation of this type of study, although its inauguration in this field was only in 2000.\nILSAs are characterized by the deployment of their surveys throughout the world, covering various countries and regions. When their results are published, they are usually illustrated in a ranking format, which opens the way to comparisons between the educational systems that were part of such studies. Therefore, the ILSAs are seriously considered in the field of both research and public policy, since those countries that did not obtain good results look at those that scored higher to develop strategies to improve the country in the relevant area. However, there are criticisms in relation to the above, because there could be situations in which a government decides to implement a policy identically inspired by another country, without considering the particularities of its region, which would lead to a probable failure of the project (johanssonInternationalLargescaleAssessments2016?).\nOn the other hand, ILSAs are usually framed around specific themes, but considering the effects that contextual factors at the country, school, classroom and student level may have on achievement. For this reason, the questionnaires are not only directed at students, but there may also be some that seek to gather information from the school, teachers or family of the main respondents. Because of this, ILSA data are rich in terms of the uses and treatments that can be given to them. From the data structure, statistical analysis techniques of some complexity such as multilevel models or structural equation models, to name a few, could be employed."
  },
  {
    "objectID": "06_ilsa.html#ilsas-on-digital-issues",
    "href": "06_ilsa.html#ilsas-on-digital-issues",
    "title": "5  International Large-Scale Asessments and Digital Issues",
    "section": "5.2 ILSAs on Digital Issues",
    "text": "5.2 ILSAs on Digital Issues\nIn recent years, Information and Communication Technologies4 have become vitally relevant to life in society as they are increasingly present in all spheres of existence, due to the dizzying pace of technological development. In this context, a number of questions have arisen as to how young people relate to technology, and whether they are really prepared to cope in an increasingly digitized world.\nIn this context, the use of new technologies in education is a topic in vogue, due to the potential benefits that their implementation could bring in this area, such as learning flexibility, the creation of new learning and interaction environments, and the transformation of the traditional training scenario, among many others (caberoalmenaraAlfabetizacionDigitalAlumnos2008?). However, if these technologies are not democratized in terms of access and knowledge for proper use, societies could be more vulnerable to fragmentation in the digital environment (truccoNuevasTecnologiasInformacion2010?).\nThus, digital literacy is seen as a common objective on the horizon by a vast number of countries, which is reflected in the numerous initiatives that have emerged, especially since the beginning of the new millennium, to promote this type of literacy among citizens. Milestones such as the World Summit on the Information Society held in 2003 and 2005, or the i2010 plan carried out by the European Union, have set the tone for joint efforts among countries to promote advances in societies in terms of technology, seeking to promote access to it and the knowledge necessary for citizens to take advantage of its benefits (echeverriaezpondaTICRelacionesEntre2010?).\nThis growing relevance of digital literacy in society has caused that in recent years the digital issue has become an important part of the ILSA agenda, including questions of this type in their questionnaires, in order to elucidate the conditions in which young people find themselves with respect to their knowledge and skills in digital technologies. In this context, the attitudes and dispositions that young people have towards ICTs have become very important, highlighting self-efficacy in this area.\nIt becomes necessary to understand the current context in relation to emerging technologies and the skills to benefit from them. At a general level, the ILSAs have established a prioritization of this, which is highly valuable, since, thanks to the global scope of these studies, a panorama could be visualized at both national and international levels, which would consequently lead to the planning of strategies aimed at addressing the weakest points identified thanks to the ILSAs."
  },
  {
    "objectID": "06_ilsa.html#references",
    "href": "06_ilsa.html#references",
    "title": "5  International Large-Scale Asessments and Digital Issues",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "06_ilsa.html#footnotes",
    "href": "06_ilsa.html#footnotes",
    "title": "5  International Large-Scale Asessments and Digital Issues",
    "section": "",
    "text": "Hereinafter, ILSAs↩︎\nHereinafter, IEA↩︎\nHereinafter, OECD↩︎\nHereinafter, ICTs↩︎"
  },
  {
    "objectID": "07_icils_timss_pisa.html#about-icils-timss-and-pisa",
    "href": "07_icils_timss_pisa.html#about-icils-timss-and-pisa",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "6.1 About ICILS, TIMSS and PISA",
    "text": "6.1 About ICILS, TIMSS and PISA\nWithin ILSAs, there are two major organizations that have promoted this type of study: the IEA and the OECD. On the one hand, the IEA is the association in charge of leading and conducting two of the most important large-scale assessment studies: International Computer and Information Literacy Study 1 and Trends in International Mathematics and Science Study 2. On the other hand, the OECD is the orchestrator of the Programme for International Student Assessment 3, one of the leading ILSAs in the world. These three studies share the same target population in that they focus on adolescents, specifically young people between the ages of 13 and 15. More importantly, all of the aforementioned studies contain a digital self-efficacy battery, so the following paragraphs will seek to describe at a general level each of the ILSAs, and then to show how they address digital self-efficacy in their evaluative frameworks. Subsequently, a comparative analysis will be made between the digital self-efficacy batteries between cycles of the same study, as well as between different studies, to finally propose a discussion on the successes and failures in the different measurements that have been proposed regarding digital self-efficacy.\nICILS is a study on digital literacy, which seeks to answer the question: How well are students prepared to study, work and live in a digital world? To this end, the study measures achievement in computer and information literacy (CIL), a concept defined as “an individual’s ability to use computers to investigate, create, and communicate in order to participate effectively at home, at school, in the workplace, and in society” (julianfraillonIEAInternationalComputer2013?). It is worth mentioning that this concept is operationalized by ICILS in order to measure digital literacy. The study deploys a complex sample design involving multistage, stratified and cluster sampling techniques (see p.59, julianfraillonSampleDesignImplementation2020?).\nThe first ICILS study cycle was conducted in 2013. It involved 22 educational systems, and was the inaugural milestone of the study that seeks to measure achievement in CIL (see on official website). Subsequently, the second cycle of the study occupied 2018, covering only 13 countries, but Computational Thinking domain was added as one of the key aspects to be studied. Currently, the report of the results of the third cycle of the study was recently published, which was conducted in 2023, while the databases will be officially released in March of this year.\nThe second study to be analyzed in this paper is TIMSS, which is conducted by the IEA and PIRLS International Study Center at Boston College’s Lynch School of Education and Human Development. This ILSA, as its name implies, focuses on assessing the performance of fourth and eighth grade students in mathematics and science. In addition, it contains questions related to the students’ context.\nThe first TIMSS study was carried out in 1995 and has been conducted periodically every 4 years without fail. Regarding the most recent cycles, it is worth mentioning that TIMMS 2019 was attended by 72 educational systems, while the subsequent cycle carried out in 2023 repeated the same number of participants (see on official website). The results of the eighth and final cycle of the study have recently been published, and the next cycle, which is scheduled for 2027, is already in sight. It is important to mention that the sample design of this study is based on a two-stage stratified random sampling, with the sample of schools as the first stage and the selection of the classes of students in each school as the second stage (see p. 3.1, siegelp.TIMSSSampleDesign2024?)\nRegarding the approach to technology in their questionnaires, in the 2011 cycle we found for the first time the presence of questions on this topic, although they only referred to the frequency of computer use at home and at school.\nFinally, there is PISA, a study that is organized and executed by the OECD. PISA is characterized by measuring the abilities of 15-year-old adolescents to use their knowledge in reading, mathematics and science to face challenges in real life. This ILSA stands out for the great thematic versatility of its questionnaires. For example, the 2022 cycle contained 7 surveys, which dealt with topics such as financial literacy or good living. In addition, in each cycle of the study, one domain area takes center stage. Particularly, in 2018, the area of reading predominated, while the 2022 study focused especially on the mathematical area.\nPISA originated in 2000, and since that year the study has been carried out periodically every 3 years. The only cycles that escape this rule are those of 2022 and 2025 (next to be carried out), since the pandemic and the subsequent cancellation of face-to-face classes prevented the surveys from being duly deployed in 2021. For this reason, the eighth cycle of PISA (2021 initially) was postponed to the following year, consequently affecting the date of the subsequent cycle. A noteworthy aspect is that since the first PISA cycle, space has been given to familiarity with technology.\nThis study implements a two-stage stratified sample design. The first stage were schools that had 15-year-old students to be surveyed, as the second sampling units were the students within sampled schools (see p. 104, oecdPISA2022Technical2024?). In terms of participation levels in the latest studies, the cycle conducted in 2018 had 79 countries and economies, while the study conducted in 2022 was made up of 81 participants. Both cycles included OECD and non-OECD members.\nA striking aspect of PISA is that from the beginning of the study they have contemplated a questionnaire on familiarity with technology. Due to rapid technological transformations, this questionnaire has undergone constant modifications. Nevertheless, digital self-efficacy appears as an inconsistent item in the different PISA cycles. In both 2000 and 2009 digital self-efficacy is absent in the questionnaires, however, in all other cycles it is present.\nEach study has extensive documentation that is open access, which can be found on their respective web pages. There, the implemented questionnaires, technical reports, databases, among other files, can be viewed and downloaded. The openness of their data is of great value, since it allows them to be analyzed in order to generate knowledge in various fields, such as academia or public policy.\nSimilarly, it is extremely important to clarify that both TIMMS and PISA use characterization questionnaires as the only resource to address digital issues, which, ultimately, does not allow measuring the competencies or skills of respondents. Not so ICILS, which, in addition to covering characterization elements, deploys a standardized performance assessment test, which has the objective that digital literacy can be measured in a concrete way."
  },
  {
    "objectID": "07_icils_timss_pisa.html#how-this-studies-adress-digital-self-efficacy",
    "href": "07_icils_timss_pisa.html#how-this-studies-adress-digital-self-efficacy",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "6.2 How this studies adress Digital self-efficacy?",
    "text": "6.2 How this studies adress Digital self-efficacy?\nICILS, being focused on digital issues, does not have a specific section of the document dealing with it, but the document is framed in this topic. However, the evaluation framework of this study contains a chapter focused on contextual determinants, which is subdivided into the types of context that influence computer and information literacy, such as home context, school context, and individual context. The latter includes attitudinal and behavioral factors. Self-efficacy is placed in this framework.\nTo conceptualize self-efficacy, the study paraphrases Bandura’s (1993) definition, stating that self-efficacy is students’ confidence in their own ability to perform tasks in a specific area (Bandura, 1993, as cited in julianfraillonIEAInternationalComputer2013?). In this way, it is made explicit that the questionnaire aims to measure the confidence expressed by students when performing ICT-related tasks. In this sense, ICILS employs the concept of ICT self-efficacy. In addition, the previous wave of the study is mentioned, emphasizing the identification of two dimensions of self-efficacy: basic and advanced. In this study, they will continue with this distinction. Finally, literature is presented that supports the idea that self-efficacy is a relevant variable for predicting achievement, in this case, in computational and information literacy (see p. 41, fraillonContextualFramework2019?).\nPISA has an ICT assessment framework, which considers 3 dimensions: ICT uses; ICT access and ICT competencies of students. The latter specifies the most relevant competencies identified in existing assessment frameworks on digital literacy. It is worth mentioning that the framework provided by PISA goes in the direction of laying the foundations for, in the future, being able to integrate ICT literacy as a specific domain in its study. Therefore, the document defines ICT literacy as “the interest, attitude and ability of individuals to appropriately use digital technologies and communication tools to access, manage, integrate and evaluate information, construct new knowledge, and communicate with others in order to participate effectively in society” (Lenon et al., 2003, as cited in oecdPISA2022ICT2023?). This definition is not original to PISA, but resorts to the conceptualization of Lenon et al. (2003).\nICT competencies include knowledge, understanding, attitudes, dispositions and skills. Self-efficacy is among the attitudes and dispositions towards ICT. In greater depth, the 5 main areas of ICT competencies are: accessing, managing and evaluating information and data (1); sharing information and communicating (2); transforming and creating digital content (3); individual and collaborative problem solving in digital contexts, and computational thinking (4); appropriate use of ICT (knowledge and skills related to safety, security and risk awareness) (5). In this context, it is made explicit that the measure of self-efficacy is the main assessment instrument for ICT competencies.\nIt is worth mentioning that PISA does not explicitly define “digital self-efficacy” but treats self-efficacy throughout the document in the framework of attitudes and dispositions towards ICT, so that a specific concept of self-efficacy is absent (see p. 277, oecdPISA2022ICT2023?).\nTIMMS is the study with the least extensive evaluation framework on digital issues, so it can be assumed that it is not a section that has been prioritized in the questionnaire. Instead, information on student performance in mathematics and science prevails.\nThe TIMMS cycle conducted in 2019 conceptualizes self-efficacy as “Student confidence using technology”, being considered in the section “Student attitudes toward learning”, where student attitudes toward mathematics and science are also highlighted (see pp. 72, inav.s.mulllisTIMSS2019Context2019?). Subsequently, in the 2023 cycle of the same study, the concept is changed to “digital self-efficacy”, which is framed in the section “Information technologies and digital services”. In it, two variables are specified: uses of digital services (1) and digital self-efficacy (2). In neither of the two cycles is there a previous contextualization that supports the presentation of these topics, nor a deep justification of why self-efficacy in digital issues is relevant. Nor is there a conceptualization of self-efficacy as such. Despite all these gaps, the study does employ a specific concept in both of its two cycles (see p. 59, inav.s.mulllisTIMSS2023Context2023?).\nDespite the lack of theoretical depth regarding digital self-efficacy, one of the most interesting features of TIMMS is that in addition to containing the digital self-efficacy battery, it has self-efficacy batteries for mathematics and science, which could open certain lines of research regarding this specific topic."
  },
  {
    "objectID": "07_icils_timss_pisa.html#measures-of-digital-self-efficacy",
    "href": "07_icils_timss_pisa.html#measures-of-digital-self-efficacy",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "6.3 Measures of digital self-efficacy",
    "text": "6.3 Measures of digital self-efficacy\n\n\n\n\n\n\nEstudios\nICILS.2013\nICILS.2018\nPISA.2018\nPISA.2022\nTIMSS.2019\nTIMSS.2023\n\n\n\n\nConcepto específico\nICT Self-efficacy\nICT Self-efficacy\nSelf-efficacy\nSelf-efficacy\nStudent confidence using technology\nDigital self-efficacy\n\n\nCantidad de dimensiones\n2\n2\n1\n1\n1\n1\n\n\nTipos de dimensiones\nBásica y avanzada\nGeneral y especializada\nGeneral\nGeneral\nGeneral\nGeneral\n\n\nFraseo del ítem\nHow well can you do each of these tasks on a computer?\nHow well can you do each of these tasks on a computer?\nThinking about your experience with digital media and digital devices: to what extent do you disagree or agree with the following statements?\nTo what extent are you able to do the following tasks when using &lt;digital devices&gt;?\nHow much do you agree with these statements?\nHow much do you agree with these statements?\n\n\nÍtems que componen la batería\nBásica\nGeneral\nGeneral\nGeneral\nGeneral\nGeneral\n\n\nÍtems que componen la batería\n1) Search for and find a file on your computer\n1) Edit digital photographs or other graphics images\n1) I feel comfortable using digital devices that I am less familiar with\n1) Search for and find relevant information online\n1) I am good at using a computer\n1)I can write and edit text on a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n2) Edit digital photographs or other graphic images\n2) Write or edit a text for a school assignment\n2) If my friends and relatives want to buy new digital devices or applications, I can give them advice\n2) Asses the quality of information you found online\n2) I am good at typing\n2)I can create school presentations using a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n3) Create or edit documents (for example assignments for school)\n3) Search for and find relevant information for a school project on Internet\n3) I feel comfortable using digital devices at home\n3) Share practical information with a group of students\n3) I can use a touchscreen on a computer, tablet or smartphone\n3)I can create, tables, charts and graphs using a computer, tablet or smartphone\n\n\nÍtems que componen la batería\n4) Search for and find information you need on the Internet\n4) Create a multimedia presentation (with sound, pictures, or video)\n4) When I come across problems digital devices, I think I can solve them\n4) Collaborate with other students on a group assesment\n4) It is easy for me to find information on the Internet\n4)I can find information that I need online\n\n\nÍtems que componen la batería\n5) Create a multi-media presentation (with sound, pictures, or video)\n5) Upload text, images, or video to an online profile\n5) If my friends and relatives have a problem with digital devices, I can help them\n5) Explain to other students how to share digital content online on or a school platform\n5) I can look up the meanings of words on Internet\n5)I can tell if a website is trustworthy\n\n\nÍtems que componen la batería\n6) Upload text, images or video to an online profile\n6) Insert an image nto a document or message\n6) If I need new softare, I install it by myself\n6) Write or edit text for a school assignment\n6) I can write sentences and paragraphs using a computer\n6)I can easily do new things on computers, laptops or smartphones\n\n\nÍtems que componen la batería\n\n7) Install a program or [app]\n7) I read information about digital devices to be independent\n7) Collect and record data (e.g. using data loggers, &lt;Microsoft Access&gt;, &lt;Google form&gt;, spreadsheets)\n7) I can edit on a computer\n7)I can help my friends or family members with using their computers, laptops and smartphones\n\n\nÍtems que componen la batería\n\n8) Judge whether you can trust information you find on internet\n8) I use digital devices as I want to use them\n8) Create a multimedia presentation (with sound, pictures and video)\n\n\n\n\nÍtems que componen la batería\n\n\n9) If I have a problem with digital devices I start to solve it on my own\n9) Create, update and mantain a webpage or blog\n\n\n\n\nÍtems que componen la batería\n\n\n10) If I need a new application, I choose it by myself\n10) Change the setting of a device or app in order to protect my data and privacy\n\n\n\n\nÍtems que componen la batería\n\n\n\n11) Select the most efficient programme or app that allows me to carry out a specific task\n\n\n\n\nÍtems que componen la batería\n\n\n\n12) Create a computer program (e.g. in &lt;Scratch&gt;, &lt;Python&gt;, &lt;Java&gt;)\n\n\n\n\nÍtems que componen la batería\n\n\n\n13) Identify the source of an error in a software afeter considering a list of potential causes\n\n\n\n\nÍtems que componen la batería\nAvanzada\nEspecializada\n\n\n\n\n\n\nÍtems que componen la batería\n1) Use software to find and get rid of viruses\n1)Create a database (e.g., using [Microsoft Access])\n\n\n\n\n\n\nÍtems que componen la batería\n2) Create a database (for example using [Microsoft Access])\n2)Build or edit a webpage\n\n\n\n\n\n\nÍtems que componen la batería\n3) Build or edit a webpage\n3)Create a computer program, or [app] (e.g., in [Basic, Visual Basic])\n\n\n\n\n\n\nÍtems que componen la batería\n4) Change the settings on your computer to improve the way it operates or to fix problems\n4)Set up a local area network of computers or other ICT\n\n\n\n\n\n\nÍtems que componen la batería\n5) Use a spreadsheet to do calculations, store data or plot a graph\n\n\n\n\n\n\n\n\n6) Create a computer program or macro (for example in [Basic, Visual Basic])\n\n\n\n\n\n\n\n\n7) Set up a computer network\n\n\n\n\n\n\n\nCategorías de respuesta\nI know how to do this (1); I could work out how to do this (2); I do not think I could do this (3)\nI know how to do this (1); I could work out how to do this (2); I do not think I could do this (3)\nStrongly disagree (1); Disagree (2); Agree (3); Strongly agree (4)\nI cannot do this (1), I struggle to do this on my own (2), I can do with a bit of effort (3), i can easily do this (4), I don´t know what this is (5)\nAgree a lot (1); Agree a little (2); Disagree a little (3); Disagree a lot (4)\nAgree a lot (1); Agree a little (2); Disagree a little (3); Disagree a lot (4)\n\n\nDiferencias entre ciclo\nDimensiones de autoeficacia Enunciados de las baterías\nDimensiones de autoeficacia Enunciados de las baterías\nFraseo del ítem Enunciados de las baterías Categorías de respuesta\nFraseo del ítem Enunciados de las baterías Categorías de respuesta\nConcepto de autoeficacia Enunciados de las baterías\nConcepto de autoeficacia Enunciados de las baterías\n\n\n\n\n\n\n\nTable 3 shows the digital self-efficacy batteries belonging to the last two cycles of each study mentioned above, including some of their characteristics such as item phrasing and/or response categories. This was done in order to illustrate the differences that exist between the different cycles of a study, as well as the differences between studies.\nFirstly, in ICILS, it can be observed that the specific concept with which they deal with digital self-efficacy has been maintained, using “ICT Self-efficacy” in its two cycles. Likewise, both the item phrasing and the response categories that were proposed in the first cycle of the study remained unchanged in the second cycle.\nOn the contrary, the change in the conceptualization of the type of ICT self-efficacy dimensions stands out, since, while in the 2013 cycle they were defined as “basic and advanced”, in the 2018 cycle this was modified to “general and specialized”. Now, the most significant change is in the items that make up the ICT Self-efficacy batteries in the two cycles. In the basic-general dimension, for the 2013 cycle there are 6 items, finding a tendency towards digital editing and searching tasks, while in the 2018 cycle there are 8 items in total, including topics of program installation and information evaluation. On the other hand, in the advanced-specialized dimension there is a decrease of items when comparing the first and second cycle. In 2013 this battery was made up of 7 items, and in 2018 only 4, leaving aside tasks such as removing viruses from a computer or using spreadsheets.\nThe digital-themed self-efficacy batteries in PISA change almost all of their characteristics from one cycle to the next, only keeping the understanding of self-efficacy on a single dimension. First, the item phrasing in the 2018 cycle attends to the extent to which the respondent agrees or disagrees with the statements to be presented. In contrast, in the 2022 cycle it refers to the extent to which the respondent is able to perform the tasks that will be presented. These changes in the phrasing of the item also have implications for the response categories of the cycles, since they point to different questions. For the 2018 cycle the responses are based on a scale ranging from “strongly disagree” to “strongly agree,” while the response categories for the last cycle range from “I cannot do it” to “I can do it easily.”\nThe items of the PISA batteries also underwent several changes. First, the 2022 cycle has 3 more items compared to the 2018 cycle. To elaborate on this, the items of the first cycle of this study are mainly made up of statements that allude to the feeling of comfort with the use of digital services, as well as tasks that point to autonomy in the digital sphere. In contrast, the 2022 items focus on task performance, including skills ranging from practical knowledge to critical evaluation. In addition, it can be generally noted that the battery is constructed in such a way that the first items point to tasks that do not demand great complexity, while the last items require much more in-depth knowledge and skills in the digital domain.\nThe measurement of digital self-efficacy in TIMSS has maintained certain characteristics, specifically the consideration of a single self-efficacy dimension, item phrasing and subsequent response categories. The question that supports this battery expresses the degree to which one agrees with the statements, so the response categories range from “strongly agree” to “strongly disagree”.\nNow, the concept with which self-efficacy in digital subjects is treated is different between the two TIMMS cycles. For the 2019 cycle the concept “Student confidence using techonology” was used, which in the 2023 cycle would change to “Digital Self-efficacy”.\nAnother aspect that underwent modifications was the construction of the digital self-efficacy batteries. In the previous cycle, the battery consisted of 7 items, which focused on practical tasks of a low level of complexity; among them, “being good at typing” or “being able to use a touchscreen”. In TIMSS 2023, the same number of items are observed, but they address tasks that require greater knowledge in the field, such as creating presentations or graphics, or feeling able to help others in the use of digital services.\nBetween ICILS, PISA and TIMSS, major differences can be noted in terms of the characteristics of their self-efficacy batteries in the digital domain. First, TIMSS is the only study that has modified the conceptualization of self-efficacy in relation to technology. However, ICILS stands out for comprising two dimensions of digital self-efficacy, whereas the other studies only take into account one generalized dimension. On the other hand, the item phrasings and the response categories derived from them differ between each study. The closest studies in these measurement characteristics are PISA 2018 with the two TIMMS cycles when measuring the degree of agreement.\nThe greatest differences are found in the items that make up the digital self-efficacy batteries. Each study has undergone transformations in the items that make up the batteries, some including a greater number of statements, or adding tasks of greater complexity and omitting aspects that were measured in their respective previous cycles.\nThis section conducted a comparative analysis of the construction of the digital self-efficacy batteries, observing the items that constitute such batteries in the different cycles of the different studies, as well as the differences presented intra-cycle and intra-study. The next section seeks to deepen the analysis of how self-efficacy in digital issues has been measured in the studies presented in the document, through an evaluation based on the conceptual framework provided by Bandura, which was presented in the first part of this working paper."
  },
  {
    "objectID": "07_icils_timss_pisa.html#references",
    "href": "07_icils_timss_pisa.html#references",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "07_icils_timss_pisa.html#footnotes",
    "href": "07_icils_timss_pisa.html#footnotes",
    "title": "6  ICILS, TIMSS and PISA. Three opportunities to approach Digital Self-efficacy",
    "section": "",
    "text": "Hereinafter, ICILS↩︎\nHereinafter, TIMSS↩︎\nHereinafter, PISA↩︎"
  },
  {
    "objectID": "08_hits_misses.html#a-comparison-of-operazionalization-strategies",
    "href": "08_hits_misses.html#a-comparison-of-operazionalization-strategies",
    "title": "7  Hits and misses in ILSA’s digital Self-efficacy approaches",
    "section": "7.1 A comparison of operazionalization strategies",
    "text": "7.1 A comparison of operazionalization strategies\nAs can be read, these three ILSA studies have different theoretical approaches to Digital Self-efficacy. Because of their limitations, one of them will likely focus on some dimensions of the concept of self-efficacy and another on other elements. The following section is a comparative analysis of the orientations and definitions of each study in relation to the conceptual discussions of Self-efficacy.\nICILS presents a task orientation on self-efficacy concept in both cycles it presents. The questions ask if students can or cannot do concrete activities with technologies, leaving out self-regulatory elements of the concept. In the items there’s not query on levels of confidence or comfortability in the doing-task process. In that sense, ICILS focus on the magnitude of task achievement over strength. The concern is around the grades or levels of masterization on digital devices handling in isolation. This same approach explains why is the unique ILSA which divides a priori the Self-efficacy batteries in two: the first for a minus level of complexity in the masterization and the second for a more advance state of that process.\nBoth batteries of this study in 2013 and 2018 cycles are named as ‘ICT Self-efficacy’, which is consistent with the development of the debate on digital Self-efficacy (ulfert-blankAssessingDigitalSelfefficacy2022?). 2010’s were the epoche were Computer and Internet Self-efficacy were synthetized with ICT self-efficacy. It is noticeable that ICILS’ scales not only measure technical or informative tasks (as do the Computer self-efficacy approach), such as application development or file manipulation, but also others of evaluative nature and digital content creation. Likewise, it’s important to note that the scale is computer-device oriented, most of the tasks listed cannot be done in smartphones or other digital systems less powerful to process information.\nICILS’s statement again demonstrates its focus on digital literacy over a comprehensive understanding of digital competences. The question looks at “How well” the task is done, seeking to orient the concept to a sense of neatness or perfection of accomplishment, over levels of confidence in the process. Regarding the phrasing of the responses, ICILS has a battery consistent with the recommendations of the specialized literature on self-efficacy measurements (banduraGuideConstructingSelfefficacy2006?; pajaresChapter1Self2002?; williamsConfoundedSelfEfficacyConstruct2016?), in that it avoids can-do statements, and opts for a strategy that divides individuals who declare they know from those who declare they do not know but believe they could learn, as well as those who declare they are unable to do so. However, the relatively categorical nature with which the battery responses are composed tends to limit the analysis of individuals’ nuances and degrees of self-efficacy, and also have the problem of asking about future capabilities and no actual ones (banduraGuideConstructingSelfefficacy2006?).\nPISA presents an inconsistent approach to measuring self-efficacy. In the 2018 version, both the statement and the items refer to the self-regulatory dimension of the concept, specifically with coping self-efficacy. The statement puts the individual in a context when asking for his or her own experience with digital devices. Then, some items ask explicitly for levels of comfort and others encourage the individuals to think about their own interpersonal relations (friends, family, etc.) before they judge their own level of self-efficacy. 2023 version makes a qualitative leap. The scale opts for a battery more similar to ICILS approach, where the statement assumes individual isolation, and the items identify concrete digitally mediated tasks to be solved.\nAlthough PISA does not add to its documentation a specific terminology to refer to digital self-efficacy, it is clear that in 2018 they presented a rather fuzzy concept approaching self-efficacy for the general use of digital devices, which does not specify specific tasks applicable in different systems. In that sense, it is difficult to encapsulate this proposal within the debate identified by (ulfert-blankAssessingDigitalSelfefficacy2022?). In the case of 2022, the items presented are in tune with the most recent Digital self-efficacy concept, as identify not only digital literacy aspects but digital creation, security and problem-solving too, independently of digital systems. If the analysis enters in details, even if the approach connect with actual standards and suggestions to measure the concept, in any case does not take into account the complexity of security and problem-solving dimensions, leaving only one minimal item for both competences.\nWith respect to the response wording, PISA proposals let researchers delve into numerical levels of self-efficacy, as they present more than three alternatives, with a clearly ordinal disposition. In both cycles, the responses determine grades of agreement in the achievement of the tasks deployed using the strategy suggested by (banduraGuideConstructingSelfefficacy2006?) and (williamsConfoundedSelfEfficacyConstruct2016?) of not dichotomizing between being able or not being able to do the task, but rather establishing levels of security to be able to achieve it. Altough, in 2018 the categories have an bipolar scale which is not aligned with (banduraGuideConstructingSelfefficacy2006?) standard of unipolar scales recommendations.\nTIMMS declares explicitly the adoption of the ‘Digital Self-efficacy’ terminology, but this does not guarantee that it complies with the multidimensional and heterogeneous standards (ulfert-blankAssessingDigitalSelfefficacy2022?) suggests. The 2019 cycle have a very basic and minimalistic approach to digital efficacy expectancy. The tasks measured are excessively general and simple, as ‘use a touchscreen’ or ‘edit on a computer’. Although the items phrasing shows that the scale has a good balance between task and self-regulatory approach to self-efficacy, results to be are so abstract that they lose their specificity. The 2023 cycle presents major levels of complexity, but ignores tasks out of informational, evaluative, or creative skills with technologies, such as problem-solving or security. The battery is short and does not allow for a deeper dive into the concept of digital self-efficacy as discussed by (ulfert-blankAssessingDigitalSelfefficacy2022?).\nAs PISA, TIMMS in both cycles subscribe to a bipolar level of agreement on task achievement strategy which is not aligned with (banduraGuideConstructingSelfefficacy2006?) assessments. The measure let identify grades of Self-efficacy, but not distinguishing whether individual can/cannot achievement or not (For this, a scale from 0 to a maxium level have to be used).\nIn summary, it can be pointed out that ICILS emphasizes to a greater extent the ICT operational and technical aspects of the technologies, proposing two measures that linearly increase the degrees of complexity of the tasks, and excluding the attitudinal aspect in this process. While PISA details to a greater extent the mechanisms of self-regulation that accompany the concept of self-efficacy and Digital Competence, although it presents inconsistencies between its cycles. And finally, TIMMS has a minimalist strategy that does not give enough emphasis to digital self-efficacy to deepen the debates surrounding the concept."
  },
  {
    "objectID": "08_hits_misses.html#suggestions-from-team-nudos",
    "href": "08_hits_misses.html#suggestions-from-team-nudos",
    "title": "7  Hits and misses in ILSA’s digital Self-efficacy approaches",
    "section": "7.2 Suggestions from Team NUDOS",
    "text": "7.2 Suggestions from Team NUDOS\nUna vez que discutamos en profundidad estos resultados, sería pertinente armar una propuesta o sugerencias para los tres estudios ILSA que vaya acorde a sus enfoques… (Este trabajo queda en pendiente pues requiere de juntarnos y acumular ideas en conjunto)."
  },
  {
    "objectID": "08_hits_misses.html#references",
    "href": "08_hits_misses.html#references",
    "title": "7  Hits and misses in ILSA’s digital Self-efficacy approaches",
    "section": "7.3 References",
    "text": "7.3 References"
  },
  {
    "objectID": "09_digital_divide_framework.html#digital-divide-framework",
    "href": "09_digital_divide_framework.html#digital-divide-framework",
    "title": "8  Digital Divide Framework",
    "section": "8.1 Digital divide framework",
    "text": "8.1 Digital divide framework\nIn this section, the ideas of (lythreatisDigitalDivideReview2022?) related to the concept of digital divide will be summarized. This is relevant to address since it provides us with a conceptual framework and bibliography to understand the digital inequalities, potentially addressed in this agenda. This chapter may potentially be expanded to include a more extensive historical overview of the concept, as well as the various approaches, criticisms, and proposals related to it.\nThe concept of the digital divide, coined by scholars during the 1990s, refers to the various gaps in access, usage, and outcomes associated with Information and Communication Technologies (ICT). The digital divide has gained increasing prominence due to the rise of the digital economy; the concept has been embraced by numerous organizations and public policy institutions. For instance, the United Nations places significant emphasis on ICT as a means to achieve its Sustainable Development Goals (SDGs) and combat social inequalities. The significance of the concept lies not only in its impact on individuals’ relationships with the digital world but also in its implications for social mobility, given the pervasive integration of ICT into both the labor market and educational systems. Three levels or grades of the digital divide have been proposed, each with its specific characteristics and context.\nThe first level to emerge was the most restrictive, focusing solely on disparities in ICT access within the population. This was conceptualized simply as a dichotomy between those with effective access to technology and those without.\nAt the dawn of the new millennium, scholars recognized the need to broaden the concept, as access disparities alone failed to capture the growing inequalities tied to technology and digitalization. The second level of the digital divide encompasses differences in access to relevant content, the quality of connectivity, digital knowledge and skills, attitudes, behaviors, and emotions.\nA third level of the digital divide was proposed as a critique of the assumption that equal access and use of ICT would necessarily yield equal outcomes. Consequently, it became essential to examine the benefits or consequences derived from ICT usage.\nThe concept of the digital divide has been studied through various approaches and a wide range of variables. As a result, it has been proposed to conceptualize it as a multidimensional and dynamic phenomenon, aligned with the rapid pace of technological change in contemporary society.\nThe most relevant determinants of the digital divide include age, gender, socioeconomic status, attitudes, beliefs, emotions, ICT experience and training, rights, infrastructure, and large-scale events (e.g., COVID-19).\nMoreover, recent literature has proposed new levels of the digital divide. Bartikowski et al. (2018, cited in (lythreatisDigitalDivideReview2022?)) argued that the type of internet use is a critical component of the digital divide. Cinamon (2020, cited in (lythreatisDigitalDivideReview2022?)) highlighted data inequalities as a significant but insufficiently addressed aspect of the digital divide. Gran et al. (2021, cited in (lythreatisDigitalDivideReview2022?)) introduced a new fourth level of the digital divide, which examines the positive and negative effects of algorithms on individuals. Awareness of and access to information about algorithms could become a crucial societal issue, particularly as algorithms assume a significant role in public participation, posing a challenge to democracy.\nIntegrating this research agenda into the broader literature on the digital divide is essential. Self-efficacy aligns with the second level of the digital divide but is also proposed as a significant predictor of digital skills, directly linked to the outcomes individuals can achieve through digital technologies. Additionally, the Digital Self-Efficacy (DSE) research agenda aims to explore potential gender differences and their relationship with countries’ levels of development—a focus that aligns closely with studies on the digital divide. As a mechanism for personal reflection, self-efficacy has a strong connection with learning (and therefore with literacy and skills), particularly in today’s context of accelerated technological change, which encourages the constant acquisition of new skills. Additionally, technology-related self-efficacy is related to Internet use and adoption, presenting itself as an alternative explication of the digital divide to the classic socioeconomic reasons (eastinInternetSelfEfficacyPsychology2000b?). High self-efficacy enables individuals to adapt to the dynamic labor and educational environments and to independently learn the knowledge required by current circumstances."
  },
  {
    "objectID": "09_digital_divide_framework.html#references",
    "href": "09_digital_divide_framework.html#references",
    "title": "8  Digital Divide Framework",
    "section": "8.2 References",
    "text": "8.2 References"
  },
  {
    "objectID": "10_digital_selfeff_divide.html#first-self-efficacy-divide-access",
    "href": "10_digital_selfeff_divide.html#first-self-efficacy-divide-access",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.1 First Self-efficacy divide: access",
    "text": "9.1 First Self-efficacy divide: access\nAccess is positioned as a crucial variable for Digital Self-Efficacy (DSE), as it represents the first element of the digital divide problematized in academic studies. Recent literature highlights a positive relationship between greater access to technology and higher levels of DSE. Stone (2020) identifies a significant relationship between increased access to ICT and greater self-efficacy in the domains of basic computing, internet use, applications, and content creation. Previous studies have also documented this relationship (Tondeur, Sinnaee, Van Houtte, & Van Braak, 2011, as cited in (hatlevikStudentsICTSelfefficacy2018a?); Aesaert & Van Braak, 2014; Tsai & Tsai, 2010; Zhong, 2011, as cited in (senkbeilHowWellDoes2023?)).\nDue to the simplicity of the dichotomy between access and lack of access to technology, multiple dimensions of access disparities to ICT have been proposed. A study by (ballCallComputerRecess2020?) examines how these various dimensions relate to DSE, dividing it into Technology Self-Efficacy (TSE) and Application Self-Efficacy (ASE). Among the key findings, a significant relationship was observed between access to and use of computers at home and TSE; however, no such relationship was found with ASE."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#the-socio-economic-divide",
    "href": "10_digital_selfeff_divide.html#the-socio-economic-divide",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.2 The socio-economic divide",
    "text": "9.2 The socio-economic divide\nThe relationship between DSE and socioeconomic variables has also garnered academic interest, focusing on the connection between technological self-efficacies and factors such as cultural capital, parental education, and income. (hatlevikStudentsICTSelfefficacy2018a?) found that ICT self-efficacy significantly increases with higher socioeconomic status in 11 countries. Similarly, (chenICTrelatedBehavioralFactors2020?), using PISA 2015 data, identified a significant relationship between socioeconomic level and ICT self-efficacy, although the effect was not very strong (varying across countries between 0.0241 and 0.1678). Additionally, (chikezieMeasuringImpactSocioeconomic2024?) reported that socioeconomic status is a significant predictor of technological self-efficacy. In contrast, (stoneICTSelfEfficacyGender2020?) did not find a significant relationship between parental income (as reported by university students) and technology-related self-efficacy. Lastly, (bonanatiDigitalHomeLearning2022a?) demonstrated a relationship between parental social capital and technological self-efficacy.\nIn summary, although there is a relationship between socioeconomic status and self-efficacy, this effect ranges from low to moderate and is not consistent across all countries. For this reason, it seems important to delve deeper into this relationship, considering various factors that determine household socioeconomic status. This is particularly relevant given that socioeconomic status consistently has the most significant effect on CIL across 14 countries ((hatlevikStudentsICTSelfefficacy2018a?))."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#the-gender-divide",
    "href": "10_digital_selfeff_divide.html#the-gender-divide",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.3 The gender divide",
    "text": "9.3 The gender divide\nGender has been a significant variable in studies on Digital Self-Efficacy (DSE). It is considered important due to the historical gender digital divide across all three levels and because DSE serves as an essential predictor of Computer and Information Literacy (CIL) ((hatlevikStudentsICTSelfefficacy2018a?)). Moreover, DSE partially mediates gender differences in CIL and Computational Thinking ((camposDigitalGenderGaps2024?)). Historically, a gender gap favoring males has been observed, with men displaying higher DSE and more positive attitudes toward technology (Whitley, 1997, as cited in (caiGenderAttitudesTechnology2017a?)). However, more recent studies highlight inconsistencies in the direction of this relationship ((caiGenderAttitudesTechnology2017a?)). For instance, one study finds that men demonstrate higher technological self-efficacy (Yau and Cheng, 2012, as cited in (caiGenderAttitudesTechnology2017a?); Fraillon, 2014), another reports no significant differences (Compton, Burkett, and Burkett, 2003, as cited in (caiGenderAttitudesTechnology2017a?)), and some even indicate a reversed relationship (Compton et al., 2003, as cited in (caiGenderAttitudesTechnology2017a?); Ray et al., 1999, as cited in (caiGenderAttitudesTechnology2017a?)). As a result, numerous studies continue to scrutinize the relationship between various types of technological self-efficacy (ICT self-efficacy, internet self-efficacy, DSE, etc.) and gender.\nA meta-analysis by (caiGenderAttitudesTechnology2017a?) highlights that men exhibit better attitudes toward technology, including self-efficacy. Notably, the technological self-efficacy gap between men and women is the most reduced across years among those examined in the study. Additionally, (schererRevisitingTeachersComputer2015?), using teacher questionnaire data from ICILS 2013, identify a relationship between being male and having higher computational self-efficacy. Contrary to these findings, a study by (hatlevikStudentsICTSelfefficacy2018a?) using ICILS 2013 data reveals that women exhibit higher ICT self-efficacy, with effects ranging from 0.04 to 0.15 across nine sampled countries. Consistent with Hatlevik’s findings, Chen and Hu (2020), using PISA 2015 data, report a negative effect of being male on ICT self-efficacy, varying between -0.4369 and -0.1236 depending on the country.\nGiven the inconsistent results from studies on the relationship between gender and DSE, the construct has been segmented to better understand this complex relationship. As previously mentioned, two dimensions of DSE have been proposed: a basic dimension addressing tasks such as internet searches, communication, and social media use, and a specialized dimension involving more complex skills like programming or server management. (gebhardtStudentAchievementBeliefs2019?) and Castillo et al. (2025) (a study conducted solely in Chile) argue, using ICILS 2018 data, that women have higher basic DSE, while men score higher on average in specialized DSE.\nDeparting from studies that rely on Large Assessment Study data (which, according to this review, are predominant), (stoneICTSelfEfficacyGender2020?) developed a questionnaire comprising various batteries to measure different dimensions of technology-related self-efficacy. Administered to university applicants in the United States (n=260), the study found that women scored higher in the social media dimension (5.0 vs. 4.0, p&lt;0.01), while men scored higher in the basic computing dimension (3.79 vs. 3.48, p&lt;0.05)."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#second-divide-variables",
    "href": "10_digital_selfeff_divide.html#second-divide-variables",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.4 Second divide variables",
    "text": "9.4 Second divide variables\nThe second level of the digital divide encompasses attitudes, skills, behaviors, and technology-related uses, which recent literature highlights as significant predictors of DSE. Multiple studies have explored the relationship between specific types of ICT use, attitudes toward ICT, ICT-related learning environments, and technological self-efficacy. For instance, a study by (chenICTrelatedBehavioralFactors2020?) confirms that interest is positively and significantly related to DSE. Additionally, it finds that ICT use for leisure and socialization are important mediators of this effect, whereas ICT use at school or for school-related tasks is not. This finding is supported by numerous studies; for example, (ballCallComputerRecess2020?) demonstrates that using ICT to talk with friends or play video games significantly affects technological self-efficacy. Similarly, (horiImpactUsingICT2021?) show that ICT use in schools does not impact self-efficacy, whereas ICT use at home for learning and leisure significantly does.\nThe above suggests that the development of high technological self-efficacy in an individual occurs primarily in the home environment, particularly influenced by the context of learning, use, and types of technology usage. (bonanatiDigitalHomeLearning2022a?) explore the relationship between characteristics of the home learning environment and ICT self-efficacy. The authors reveal that children whose parents engage in more online activities with them tend to have higher self-efficacy and identify a relationship between parental attitudes and their children’s self-efficacy. In line with this, (hammerNewTechnologyNew2021?) demonstrate that parental values and beliefs are related to children’s digital self-efficacy; however, this relationship is mediated only by the age at which children are given smartphones. Relatedly, (laiClassesProblematicSmartphone2022?) argue that greater smartphone use is positively associated with DSE, though problematic uses and cases where the relationship is reversed also exist.\n(hatlevikStudentsICTSelfefficacy2018a?) finds that autonomous learning is positively related to ICT self-efficacy, making it the most consistently observed relationship across countries. (eastinInternetSelfEfficacyPsychology2000?) discover that outcome expectations are also linked to DSE, as is internet use experience, which is identified as the best predictor in their study."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#school-and-country-level",
    "href": "10_digital_selfeff_divide.html#school-and-country-level",
    "title": "9  Digital Self-efficacy Divide",
    "section": "9.5 School and country level",
    "text": "9.5 School and country level\nStudies addressing digital self-efficacy (DSE) typically involve different nested levels, as they are mostly conducted using data from International Large-Scale Assessments (ILSA). However, the school level is often not a significant variable. For example, (chenICTrelatedBehavioralFactors2020?) conducted a multilevel model including schools across 30 countries, finding that the intraclass correlation (ICC) was less than 0.05 in all countries, with the sole exception of Mexico. Similarly, (juhanakRelationshipAgeFirst2019?) found that the ICC was below 0.05 in all countries in their sample (using PISA 2015 data from 21 countries), concluding that only 0.09% of perceived ICT competence could be explained by school characteristics. These results are replicated in ICILS 2013, where (hatlevikStudentsICTSelfefficacy2018?) found that the variation explained by schools was less than 6% in all countries, with Turkey being the only exception. An ICC below 0.05 is commonly conceptualized as small in the context of educational studies. A previous study corroborates these findings, dating back to PISA 2003 (ICC = 0.044) and PISA 2006 (ICC = 0.05, barely reaching the threshold) (zhongAccessUsageDivide2011?).\nPossible explanations for this emerge from the literature review, suggesting that ICT use in schools, as opposed to ICT use for leisure or socialization, is not a relevant variable for explaining DSE (chenICTrelatedBehavioralFactors2020?; horiImpactUsingICT2021?; ballCallComputerRecess2020?). Additionally, one article finds that the use of ICT at home for school-related tasks is a less significant mediator than other ICT-related variables (juhanakRelationshipAgeFirst2019?). A potential hypothesis (arising purely from the author’s intuition) is that digital self-efficacy is reinforced by motivation, which, in the context of technology, might develop more robustly in leisure activities or communication-based activities, such as social media or video games. School activities, and increased ICT adoption in these, might discourage students from developing their digital skills as they associate them with an unavoidable responsibility.\nAt the country level, for similar reasons as at the school level, it is sometimes included in the analysis. Whether as an additional hierarchical level in the model or through models applied individually to each country, several studies have identified heterogeneity in self-efficacy across countries, as well as in the effect sizes of the independent variables employed. For instance, (zhongAccessUsageDivide2011?) found a higher correlation between classes at the country level than at the school level, with values of 0.077 in PISA 2003 and 0.079 in PISA 2006. However, the inclusion of the country level is usually aimed only at visualizing the heterogeneity or homogeneity of an effect, without specifically focusing on the relationship between country-level dependent variables and self-efficacy or even their effects. This is the case with studies such as those by (hatlevikStudentsICTSelfefficacy2018?) and (chenICTrelatedBehavioralFactors2020?), for example.\nHowever, future research needs to identify explanations for these differences, which intuitively could stem from various reasons. For instance, the degree of connectivity and technological infrastructure achieved in a country might be a significant factor influencing technology-related self-efficacy, as the population would have different levels of exposure to and familiarity with ICT. Thus, exploring various explanations for this heterogeneity is essential, as it is crucial to address digital inequalities between countries with differing levels of technological development."
  },
  {
    "objectID": "10_digital_selfeff_divide.html#references",
    "href": "10_digital_selfeff_divide.html#references",
    "title": "9  Digital Self-efficacy Divide",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "11_next_agenda.html#limits-on-self-efficacy-conceptualization-aplications-and-measurements",
    "href": "11_next_agenda.html#limits-on-self-efficacy-conceptualization-aplications-and-measurements",
    "title": "10  Next ideas for the research agenda",
    "section": "10.1 Limits on Self-efficacy conceptualization: aplications and measurements",
    "text": "10.1 Limits on Self-efficacy conceptualization: aplications and measurements"
  },
  {
    "objectID": "11_next_agenda.html#methods-studying-digital-self-efficacy-differences",
    "href": "11_next_agenda.html#methods-studying-digital-self-efficacy-differences",
    "title": "10  Next ideas for the research agenda",
    "section": "10.2 Methods studying Digital Self-Efficacy differences",
    "text": "10.2 Methods studying Digital Self-Efficacy differences\nThroughout the literature review, a multitude of methodological tools have been identified as useful for the DSE agenda of NUDOS. The vast umajority of the studies reviewed involve multilevel models and, at times, structural equation modeling, due to the availability of school-level data in ILSAs and the effort to explore mediators of relationships already demonstrated in the literature. Additionally, periodic meta-analyses that synthesize findings from previous research are evident.\nThe study by (hatlevikStudentsICTSelfefficacy2018a?), the most relevant one with ICT self-efficacy as the dependent variable, conducts a path analysis, a multivariate model that allows the inclusion of multiple independent and dependent variables simultaneously. It seeks to identify the main determinants of ICT self-efficacy and, additionally, the relationship between digital literacy and digital self-efficacy, using ICILS 2013 data. The analysis included 14 countries. For the reporting of results, the range of effects across all countries was mentioned, with occasional emphasis on outlier cases.\nThe article by (chenICTrelatedBehavioralFactors2020?) is particularly relevant to the agenda because it uses PISA data, encompassing a large number of countries (30). The study conducts a multilevel mediation model (utilizing the school level) that does not account for relationships between mediators, assuming instead that they do not covary. The independent variable is interest in ICT, the dependent variable is ICT self-efficacy, and the mediating variables considered were ICT use at home for leisure, ICT use at home for school tasks, ICT use for socializing, and ICT use in school. Additionally, gender and the index of economic, social, and cultural status (ESCS)—the latter being readily available in the PISA database—were included as control variables. The chosen technique for mediation analysis was the parallel multiple mediator model, which allows for the inclusion of multiple mediating variables in the analysis simultaneously. Similar to Hatlevik’s article, the range of effects across the different countries was reported.\nThe paper by (camposDigitalGenderGaps2024?) may serve as an excellent roadmap for research on PISA 2022. It conducts a meta-analysis combining data from ICILS 2013, ICILS 2018, and findings from 165 different articles sourced from databases (ERIC and PsycINFO). The study’s objective is to determine the extent to which gender differences in digital skills are mediated by attitudes, analyzing heterogeneity across countries and studies. Missing data were imputed through a two-level mean-matching approach (considering background data, technology use, and attitudes toward technology), resulting in 100 datasets for each ICILS cycle. Beyond this, and of particular relevance to the Digital Self-Efficacy agenda, a variety of indices were used to explore relationships between country-level outcomes and socioeconomic development, gender inequality, and other factors. Specifically, the following indices were employed: Human Development Index, Gender Inequality Index, Global Innovation Index, and ICT Use Index. Additionally, UNESCO’s country classification was used. In total, four distinct models were executed for each attitude addressed in the study (self-efficacy, beliefs, and affect). The first was a multivariate model with simple random effects; the second was a multilevel model adding the country variable; the third was a multilevel, multivariate model capturing the average effects of direct and indirect variables and their variance at different levels; and the fourth added the aforementioned indices to the first model."
  },
  {
    "objectID": "11_next_agenda.html#knowledge-gaps-regarding-digital-self-efficacy",
    "href": "11_next_agenda.html#knowledge-gaps-regarding-digital-self-efficacy",
    "title": "10  Next ideas for the research agenda",
    "section": "10.3 Knowledge gaps regarding Digital Self-efficacy",
    "text": "10.3 Knowledge gaps regarding Digital Self-efficacy\nThe relationship between various socioeconomic, sociodemographic, and subjective variables and technology-related self-efficacy has been studied. However, there is still a need to examine diverse relationships and profiles of technology users who, to this day, are being left behind in the face of the burgeoning technological revolution. One of the most notable gaps is the lack of studies considering migration background or ethnicity as an independent variable. In other fields of study, this has been addressed; for example, a study conducted in Chile found a positive relationship between students’ migrant status and their general self-efficacy (cespedesRelationshipSelfConceptSelfEfficacy2021?). It is crucial to examine this relationship in the context of digital self-efficacy, as digital competencies have become vital for adapting to a new country and achieving economic advancement.\nSimilarly, there is a noticeable lack of studies that delve into explaining differences in ICT self-efficacy across the various countries that have participated in ILSAs. Although articles such as (camposDigitalGenderGaps2024?) incorporate indices like the Human Development Index and the ICT Use Index, they do not use digital self-efficacy as the dependent variable, and analyzing the role of the country in the development of a particular technological self-efficacy is far from being their primary objective. This issue is particularly relevant when addressing the digital divide in its broadest dimension: the global one."
  },
  {
    "objectID": "11_next_agenda.html#references",
    "href": "11_next_agenda.html#references",
    "title": "10  Next ideas for the research agenda",
    "section": "References",
    "text": "References"
  }
]